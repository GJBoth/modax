{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we verify the custom backprop we've implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "from functools import partial\n",
    "from jax import lax\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from code import fwd_solver, bayes_ridge_update#, #fixed_point_layer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from jax.test_util import check_grads\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jnp.load('test_data.npy', allow_pickle=True).item()\n",
    "y, X = data['y'], data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, ))\n",
    "def fixed_point_layer(f, params, x):\n",
    "    z_star = fwd_solver(\n",
    "        lambda z: f(params, x, z), z_init=jnp.stack([1, 1 / jnp.var(params)], axis=0), tol=1e-5\n",
    "    )\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_layer_fwd(f, params, x):\n",
    "    z_star = fixed_point_layer(f, params, x)\n",
    "    return z_star, (params, x, z_star)\n",
    "\n",
    "def fixed_point_layer_bwd(f, res, z_star_bar):\n",
    "    params, x, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    return vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar, z_init=jnp.zeros_like(z_star), tol=1e-5))\n",
    "\n",
    "fixed_point_layer.defvjp(fixed_point_layer_fwd, fixed_point_layer_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = jax.jit(fixed_point_layer, static_argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_terms = X.shape\n",
    "hyper_prior =  jnp.stack([n_samples / 2, 1 / (n_samples / 2 * 1e-4)],  axis=0)\n",
    "f = lambda y, X, prior: bayes_ridge_update(y, X, prior, hyper_prior)\n",
    "\n",
    "z_star = layer(f, y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.3674249, 49.686718 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = jax.vjp(lambda y, X: layer(f, y, X), y, X)[1](jnp.array([1., 0.]))\n",
    "db = jax.vjp(lambda y, X: layer(f, y, X), y, X)[1](jnp.array([0., 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-6.0546863e-06,  4.5321195e-04, -3.9698742e-04,\n",
       "             -6.0164703e-06, -4.3055079e-05,  2.2004379e-03,\n",
       "             -2.6065094e-05, -2.2817476e-06,  2.1683940e-04,\n",
       "              1.8109565e-03,  1.9534102e-05,  1.2577546e-05],            dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda X: layer(f, y, X).sum())(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init, tol):\n",
    "    z_prev, z = z_init, f(z_init)\n",
    "    while jnp.linalg.norm(z_prev - z) > tol:\n",
    "        z_prev, z = z, f(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_terms = X.shape\n",
    "hyper_prior =  jnp.stack([n_samples / 2, 1 / (n_samples / 2 * 1e-4)],  axis=0)\n",
    "f = lambda y, X, prior: bayes_ridge_update(y, X, prior, hyper_prior)\n",
    "\n",
    "z_star = fixed_point_layer(f, y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.3674248, 49.686718 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-6.0547063e-06,  4.5321378e-04, -3.9698795e-04,\n",
       "             -6.0165371e-06, -4.3054675e-05,  2.2004391e-03,\n",
       "             -2.6065547e-05, -2.2816866e-06,  2.1683845e-04,\n",
       "              1.8109567e-03,  1.9534278e-05,  1.2577598e-05],            dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda X: fixed_point_layer(f, y, X).sum())(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our custom backprop is correct :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's refactor it a little bit to make it more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, ))\n",
    "def fixed_point_solver(f, params, x, z_init, tol=1e-5):\n",
    "    z_star = fwd_solver(lambda z: f(params, x, z), z_init=z_init, tol=tol)\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_solver_fwd(f, params, x, z_init, tol):\n",
    "    z_star = fixed_point_solver(f, params, x, z_init, tol)\n",
    "    return z_star, (params, x, z_star, tol)\n",
    "\n",
    "def fixed_point_solver_bwd(f, res, z_star_bar):\n",
    "    params, x, z_star, tol = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    res = vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar, z_init=jnp.zeros_like(z_star), tol=tol))\n",
    "    return (*res, None, None)\n",
    "\n",
    "fixed_point_solver.defvjp(fixed_point_solver_fwd, fixed_point_solver_bwd)\n",
    "layer = jax.jit(fixed_point_solver, static_argnums=(0, )) # static argnums should match non_diff argnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_terms = X.shape\n",
    "hyper_prior =  jnp.stack([n_samples / 2, 1 / (n_samples / 2 * 1e-4)],  axis=0)\n",
    "z_init=jnp.stack([1, 1 / jnp.var(y)], axis=0)\n",
    "f = lambda y, X, prior: bayes_ridge_update(y, X, prior, hyper_prior)\n",
    "\n",
    "z_star = layer(f, y, X, z_init, tol=1e-4)\n",
    "jax.grad(lambda X: layer(f, y, X, z_init).sum())(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.grad(lambda z: layer(f, y, X, z).sum())(z_init)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that works, now let's implement *args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_ridge_update(prior_params, y, X, hyper_prior_params):\n",
    "    # Unpacking parameters\n",
    "    alpha_prev, beta_prev = prior_params\n",
    "    a, b = hyper_prior_params\n",
    "\n",
    "    # Preparing some matrices\n",
    "    X_normed = X / jnp.linalg.norm(X, axis=0)\n",
    "    gram = X_normed.T @ X_normed\n",
    "    eigvals = jnp.linalg.eigvalsh(gram)\n",
    "\n",
    "    # Calculating intermediate matrices\n",
    "    n_samples, n_terms = X.shape\n",
    "    gamma_ = jnp.sum((beta_prev * eigvals) / (alpha_prev + beta_prev * eigvals))\n",
    "    S = jnp.linalg.inv(beta_prev * gram + alpha_prev * jnp.eye(n_terms))\n",
    "    mn = beta_prev * S @ X_normed.T @ y\n",
    "\n",
    "    # Update estimate\n",
    "    alpha = gamma_ / jnp.sum(mn ** 2)\n",
    "    beta = (n_samples - gamma_ + 2 * (a - 1)) / (\n",
    "        jnp.sum((y - X_normed @ mn) ** 2) + 2 * b\n",
    "    )\n",
    "\n",
    "    return jnp.stack([alpha, beta], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, ))\n",
    "def fixed_point_solver(f, args, z_init, tol=1e-5):\n",
    "    z_star = fwd_solver(lambda z: f(z, *args), z_init=z_init, tol=tol)\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_solver_fwd(f, args, z_init, tol):\n",
    "    z_star = fixed_point_solver(f, args, z_init, tol)\n",
    "    return z_star, (z_star, tol, args)\n",
    "\n",
    "def fixed_point_solver_bwd(f, res, z_star_bar):\n",
    "    z_star, tol, args = res\n",
    "    _, vjp_a = jax.vjp(lambda args: f(z_star, *args), args)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(z, *args), z_star)\n",
    "    res = vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar, z_init=jnp.zeros_like(z_star), tol=tol))\n",
    "    return (*res, None, None) # None for init and tol\n",
    "\n",
    "fixed_point_solver.defvjp(fixed_point_solver_fwd, fixed_point_solver_bwd)\n",
    "layer = jax.jit(fixed_point_solver, static_argnums=(0, )) # static argnums should match non_diff argnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_terms = X.shape\n",
    "hyper_prior =  jnp.stack([n_samples / 2, 1 / (n_samples / 2 * 1e-4)],  axis=0)\n",
    "z_init=jnp.stack([1, 1 / jnp.var(y)], axis=0)\n",
    "f = lambda prior, y, X: bayes_ridge_update(prior, y, X, hyper_prior)\n",
    "\n",
    "z_star = layer(f, (y, X), z_init, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.3674249, 49.686718 ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-6.0546863e-06,  4.5321195e-04, -3.9698742e-04,\n",
       "             -6.0164703e-06, -4.3055079e-05,  2.2004379e-03,\n",
       "             -2.6065094e-05, -2.2817476e-06,  2.1683940e-04,\n",
       "              1.8109565e-03,  1.9534102e-05,  1.2577546e-05],            dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda X: layer(f, (y, X), z_init).sum())(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.00433664], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda y: layer(f, (y, X), z_init).sum())(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0., dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda tol: layer(f, (y, X), z_init, tol=tol).sum())(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda z_init: layer(f, (y, X), z_init, tol=1e-4).sum())(z_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
