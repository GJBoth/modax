{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "from flax import optim\n",
    "from modax.models import Deepmod\n",
    "from modax.training import create_update\n",
    "from modax.losses import loss_fn_pinn\n",
    "from modax.logging import Logger\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from jax.scipy.stats import gamma\n",
    "from modax.data.burgers import burgers\n",
    "from time import time\n",
    "\n",
    "from functools import partial\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataset\n",
    "x = jnp.linspace(-3, 4, 100)\n",
    "t = jnp.linspace(0.5, 5.0, 20)\n",
    "\n",
    "t_grid, x_grid = jnp.meshgrid(t, x, indexing=\"ij\")\n",
    "u = burgers(x_grid, t_grid, 0.1, 1.0)\n",
    "\n",
    "X_train = jnp.concatenate([t_grid.reshape(-1, 1), x_grid.reshape(-1, 1)], axis=1)\n",
    "y_train = u.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = Deepmod(features=[50, 50, 1])\n",
    "key = random.PRNGKey(42)\n",
    "params = model.init(key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)\n",
    "\n",
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 0.060140594840049744\n",
      "Loss step 1000: 3.848650885629468e-05\n",
      "Loss step 2000: 1.3884466625313507e-06\n",
      "Loss step 3000: 4.39812481545232e-07\n",
      "Loss step 4000: 4.0220501773546857e-07\n",
      "Loss step 5000: 3.040478304683347e-07\n",
      "Loss step 6000: 2.48571353722582e-07\n",
      "Loss step 7000: 2.749341661001381e-07\n",
      "Loss step 8000: 1.2674520633026987e-07\n",
      "Loss step 9000: 1.1675654576492889e-07\n",
      "Loss step 10000: 1.1416497613936372e-07\n"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 10001\n",
    "logger = Logger()\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, dt, theta, coeffs = model.apply(optimizer.target, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First normalize theta\n",
    "theta_normed = theta / jnp.linalg.norm(theta, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check with OLS\n",
    "jnp.linalg.lstsq(theta_normed, dt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate eigenvalues and set and initial b\n",
    "a = 1\n",
    "b = 1 / jnp.var(dt)\n",
    "\n",
    "gram = theta_normed.T @ theta_normed\n",
    "\n",
    "l = jnp.linalg.eigvalsh(gram)\n",
    "\n",
    "n_samples = theta_normed.shape[0]\n",
    "n_terms = theta_normed.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating gamma\n",
    "gamma = jnp.sum(b * l / (a + b * l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating posterior mean\n",
    "S = jnp.linalg.inv(b * gram + a * jnp.eye(n_terms))\n",
    "mn = b * S @ theta_normed.T @ dt\n",
    "\n",
    "print(mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating a and b\n",
    "a = gamma / mn.T @ mn\n",
    "b = (n_samples - gamma) / jnp.sum((dt - theta_normed @ mn)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work, now lets do it in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(alpha_, beta_, lambda_, t, Phi, gram):\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "\n",
    "    gamma_ = jnp.sum((beta_ * lambda_) / (alpha_ + beta_ * lambda_))\n",
    "    S = jnp.linalg.inv(beta_ * gram + alpha_ * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_ * S @ Phi.T @ t\n",
    "    \n",
    "    alpha_new = gamma_ / (mn.T @ mn).squeeze()\n",
    "    beta_new = (n_samples - gamma_) / jnp.sum((t - Phi @ mn)**2)\n",
    "    \n",
    "    return alpha_new, beta_new, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update(a, b, l, dt, theta_normed, gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a, b, mn), a_old, b_old = update(a, b, l, dt, theta_normed, gram), a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while jnp.linalg.norm((a - a_old)) > 1e-4:\n",
    "    (a, b, _), a_old, b_old = update(a, b, l, dt, theta_normed, gram), a, b\n",
    "    print(b - b_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.linalg.norm((b - b_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update(a, b, l, dt, theta_normed, gram)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.linalg.lstsq(theta_normed, dt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reg.fit(theta_normed, dt.squeeze()).coef_[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a - reg.lambda_) / reg.lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b - reg.alpha_) / reg.alpha_ * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets bring it all back together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def bayes_ridge_update(alpha_, beta_, lambda_, t, Phi, gram):\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "\n",
    "    gamma_ = jnp.sum((beta_ * lambda_) / (alpha_ + beta_ * lambda_))\n",
    "    S = jnp.linalg.inv(beta_ * gram + alpha_ * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_ * S @ Phi.T @ t\n",
    "    \n",
    "    alpha_new = gamma_ / (mn.T @ mn).squeeze()\n",
    "    beta_new = (n_samples - gamma_) / jnp.sum((t - Phi @ mn)**2)\n",
    "    \n",
    "    return alpha_new, beta_new, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate eigenvalues and set and initial b\n",
    "prediction, dt, theta, coeffs = model.apply(optimizer.target, X_train)\n",
    "\n",
    "a = 1\n",
    "b = 1 / jnp.var(dt)\n",
    "\n",
    "theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "gram = theta_normed.T @ theta_normed\n",
    "l = jnp.linalg.eigvalsh(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = jax.jit(partial(bayes_ridge_update, lambda_=l, t=dt, Phi=theta_normed, gram=gram))\n",
    "(a, b, _), a_old, b_old = update(a, b), a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "while jnp.linalg.norm((a - a_old)) > 1e-3:\n",
    "    (a, b, mn), a_old, b_old = update(a, b), a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put the training loop in a nice function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def bayes_ridge_update(alpha_, beta_, lambda_, t, Phi, gram):\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "\n",
    "    gamma_ = jnp.sum((beta_ * lambda_) / (alpha_ + beta_ * lambda_))\n",
    "    S = jnp.linalg.inv(beta_ * gram + alpha_ * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_ * S @ Phi.T @ t\n",
    "    \n",
    "    alpha_new = gamma_ / (mn.T @ mn).squeeze()\n",
    "    beta_new = (n_samples - gamma_) / jnp.sum((t - Phi @ mn)**2)\n",
    "    \n",
    "    return alpha_new, beta_new, mn\n",
    "\n",
    "def bayesian_ridge(dt, theta, init_vals):\n",
    "    a, b = init_vals\n",
    "    theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "    gram = theta_normed.T @ theta_normed\n",
    "    l = jnp.linalg.eigvalsh(gram)\n",
    "\n",
    "    # Making update function\n",
    "    update = jax.jit(partial(bayes_ridge_update, lambda_=l, t=dt, Phi=theta_normed, gram=gram))\n",
    "    (a, b, _), a_old, b_old = update(a, b), a, b\n",
    "    \n",
    "    # Running to convergence\n",
    "    while jnp.linalg.norm((a - a_old)) > 1e-3:\n",
    "        (a, b, mn), a_old, b_old = update(a, b), a, b\n",
    "    mn = mn / jnp.linalg.norm(theta, axis=0)[:, None]\n",
    "    return a, b, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a, b, mn = bayesian_ridge(dt, theta, init_vals=(1, 1 / jnp.var(dt)))\n",
    "print(a, b, mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(Phi, t, mn, alpha_, beta_):\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "    \n",
    "    A = alpha_ * jnp.eye(n_terms) + beta_ * Phi.T @ Phi\n",
    "    E = beta_ / 2 * jnp.sum((t - Phi @ mn)**2) + alpha_ / 2 * mn.T @ mn\n",
    "    p = n_terms / 2 * jnp.log(alpha_) + n_samples / 2 * jnp.log(beta_) - E - 1/2 * jnp.linalg.slogdet(A)[1] - n_samples / 2 * jnp.log(2 * jnp.pi)\n",
    "    return p.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence(theta, dt, mn, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets include a prior on beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def bayes_ridge_update(alpha_, beta_, lambda_, t, Phi, gram, prior_params):\n",
    "    a, b = prior_params\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "\n",
    "    gamma_ = jnp.sum((beta_ * lambda_) / (alpha_ + beta_ * lambda_))\n",
    "    S = jnp.linalg.inv(beta_ * gram + alpha_ * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_ * S @ Phi.T @ t\n",
    "    \n",
    "    alpha_new = gamma_ / jnp.sum(mn**2)\n",
    "    beta_new = (n_samples - gamma_ + 2 * (a - 1)) / (jnp.sum((t - Phi @ mn)**2) + 2 * b)\n",
    "    \n",
    "    return alpha_new, beta_new, mn\n",
    "\n",
    "\n",
    "def bayesian_ridge(dt, theta, init_vals, prior_params):\n",
    "    a, b = init_vals\n",
    "    theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "    gram = theta_normed.T @ theta_normed\n",
    "    l = jnp.linalg.eigvalsh(gram)\n",
    "\n",
    "    # Making update function\n",
    "    update = jax.jit(partial(bayes_ridge_update, lambda_=l, t=dt, Phi=theta_normed, gram=gram, prior_params=prior_params))\n",
    "    (a, b, _), a_old, b_old = update(a, b), a, b\n",
    "    \n",
    "    # Running to convergence\n",
    "    while jnp.linalg.norm((a - a_old)) > 1e-4:\n",
    "        (a, b, mn), a_old, b_old = update(a, b), a, b\n",
    "    mn = mn / jnp.linalg.norm(theta, axis=0)[:, None]\n",
    "    return a, b, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.jit(bayesian_ridge, static_argnums=(2, 3))(dt, theta, init, prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_samples = theta.shape[0]\n",
    "prior_params = (n_samples/2, 1/(n_samples/2 * 1e-4))\n",
    "init = (1, 1 / jnp.var(dt))\n",
    "a, b, mn = bayesian_ridge(dt, theta, init, prior_params)\n",
    "print(a, b, mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(Phi, t, mn, alpha_, beta_, prior_params):\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "    a, b = prior_params\n",
    "    \n",
    "    A = alpha_ * jnp.eye(n_terms) + beta_ * Phi.T @ Phi\n",
    "    E = beta_ / 2 * jnp.sum((t - Phi @ mn)**2) + alpha_ / 2 * mn.T @ mn\n",
    "    log_p = n_terms / 2 * jnp.log(alpha_) + n_samples / 2 * jnp.log(beta_) - E - 1/2 * jnp.linalg.slogdet(A)[1] - n_samples / 2 * jnp.log(2 * jnp.pi)\n",
    "    log_p += gamma.logpdf(beta_, a=a, scale=b)\n",
    "    return log_p.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence(theta, dt, mn, a, b, prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "from modax.feature_generators import library_backward, library_forward\n",
    "from modax.layers import LeastSquares, LeastSquaresMT\n",
    "from modax.networks import MLP, MultiTaskMLP\n",
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "class Deepmod(nn.Module):\n",
    "    \"\"\"Simple feed-forward NN.\n",
    "    \"\"\"\n",
    "\n",
    "    features: Sequence[int]  # this is dataclass, so we dont use __init__\n",
    "    prior_params: Tuple\n",
    "    @nn.compact \n",
    "    def __call__(self, inputs):\n",
    "        prediction, dt, theta = library_backward(MLP(self.features), inputs)\n",
    "        a, b, coeffs = bayesian_ridge(dt, theta, (1, 1 / jnp.var(dt)), self.prior_params) \n",
    "        return prediction, dt, theta, coeffs, (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataset\n",
    "x = jnp.linspace(-3, 4, 100)\n",
    "t = jnp.linspace(0.5, 5.0, 20)\n",
    "\n",
    "t_grid, x_grid = jnp.meshgrid(t, x, indexing=\"ij\")\n",
    "u = burgers(x_grid, t_grid, 0.1, 1.0)\n",
    "\n",
    "X_train = jnp.concatenate([t_grid.reshape(-1, 1), x_grid.reshape(-1, 1)], axis=1)\n",
    "y_train = u.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = Deepmod(features=[50, 50, 1], prior_params=prior_params)\n",
    "key = random.PRNGKey(42)\n",
    "params = model.init(key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_pinn_bayes_reg(params, model, x, y):\n",
    "    prediction, dt, theta, coeffs, fit_params = model.apply(params, x)\n",
    "    n_samples = prediction.shape[0]\n",
    "    a0, b0 = n_samples / 2, 1 / (n_samples / 2 * 1e-4)\n",
    "\n",
    "    sigma_ml = jnp.mean((prediction - y) ** 2)\n",
    "    tau = 1 / sigma_ml\n",
    "    MSE = neg_LL(prediction, y, tau)\n",
    "\n",
    "    Reg = -evidence(theta, dt, coeffs, fit_params[0], fit_params[1], (a0, b0))\n",
    "    prior = -jnp.sum(gamma.logpdf(beta, a=a0, scale=b0))\n",
    "\n",
    "    loss = MSE + Reg + prior\n",
    "\n",
    "    metrics = {\n",
    "        \"loss\": loss,\n",
    "        \"mse\": MSE,\n",
    "        \"reg\": Reg,\n",
    "        \"coeff\": coeffs,\n",
    "        \"tau\": tau,\n",
    "        \"beta\": fit_params[1],\n",
    "        \"alpha\": fit_params[0]\n",
    "    }\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn_bayes_reg, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 10001\n",
    "logger = Logger()\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit layers code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import jax\n",
    "from jax import random, lax, numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 10\n",
    "W = random.normal(random.PRNGKey(0), (ndim, ndim)) / jnp.sqrt(ndim)\n",
    "x = random.normal(random.PRNGKey(1), (ndim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init):\n",
    "    z_prev, z = z_init, f(z_init)\n",
    "    while jnp.linalg.norm(z_prev - z) > 1e-3:\n",
    "        z_prev, z = z, f(z)\n",
    "    return z\n",
    "\n",
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=jnp.zeros_like(x))\n",
    "    return z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00632886 -0.70152855 -0.9847213  -0.0419194  -0.6151645  -0.48185453\n",
      "  0.5783277   0.9556748  -0.08354193  0.8447265 ]\n"
     ]
    }
   ],
   "source": [
    "f = lambda W, x, z: jnp.tanh(jnp.dot(W, z) + x)\n",
    "z_star = fixed_point_layer(fwd_solver, f, W, x)\n",
    "print(z_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, 1))\n",
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=jnp.zeros_like(x))\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_layer_fwd(solver, f, params, x):\n",
    "    z_star = fixed_point_layer(solver, f, params, x)\n",
    "    return z_star, (params, x, z_star)\n",
    "\n",
    "def fixed_point_layer_bwd(solver, f, res, z_star_bar):\n",
    "    params, x, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    return vjp_a(solver(lambda u: vjp_z(u)[0] + z_star_bar,\n",
    "                      z_init=jnp.zeros_like(z_star)))\n",
    "\n",
    "fixed_point_layer.defvjp(fixed_point_layer_fwd, fixed_point_layer_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00733157 -0.81267565 -1.1407362  -0.04856092 -0.7126285  -0.55819744\n",
      "  0.66995543  1.1070877  -0.09677795  0.9785612 ]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(fwd_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init):\n",
    "    def cond_fun(carry):\n",
    "        z_prev, z = carry\n",
    "        return jnp.linalg.norm(z_prev - z) > 1e-5\n",
    "\n",
    "    def body_fun(carry):\n",
    "        _, z = carry\n",
    "        return z, f(z)\n",
    "\n",
    "    init_carry = (z_init, f(z_init))\n",
    "    _, z_star = lax.while_loop(cond_fun, body_fun, init_carry)\n",
    "    return z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00649604 -0.7015957  -0.98471504 -0.04196557 -0.61522186 -0.48183814\n",
      "  0.5783122   0.95567054 -0.08373152  0.8447805 ]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_star = fixed_point_layer(fwd_solver, f, W, x)\n",
    "print(z_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.00649604, -0.7015957 , -0.98471504, -0.04196557,\n",
       "             -0.61522186, -0.48183814,  0.5783122 ,  0.95567054,\n",
       "             -0.08373152,  0.8447805 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_layer_jit = jax.jit(fixed_point_layer, static_argnums=(0, 1))\n",
    "fp_layer_jit(fwd_solver, f, W, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.6 ms ± 35.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z_star = fixed_point_layer(fwd_solver, f, W, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 µs ± 254 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z_star = fp_layer_jit(fwd_solver, f, W, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets adapt our bayesian regression code to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init):\n",
    "    def cond_fun(carry):\n",
    "        z_prev, z = carry\n",
    "        return jnp.linalg.norm(z_prev[0] - z[0]) > 1e-3\n",
    "\n",
    "    def body_fun(carry):\n",
    "        _, z = carry\n",
    "        return z, f(z)\n",
    "\n",
    "    init_carry = (z_init, f(z_init))\n",
    "    _, z_star = lax.while_loop(cond_fun, body_fun, init_carry)\n",
    "    return z_star\n",
    "\n",
    "@jax.jit\n",
    "def bayes_ridge_update(alpha_, beta_, lambda_, t, Phi, gram, prior_params):\n",
    "    \n",
    "    a, b = prior_params\n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "\n",
    "    gamma_ = jnp.sum((beta_ * lambda_) / (alpha_ + beta_ * lambda_))\n",
    "    S = jnp.linalg.inv(beta_ * gram + alpha_ * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_ * S @ Phi.T @ t\n",
    "    \n",
    "    alpha_new = gamma_ / jnp.sum(mn**2)\n",
    "    beta_new = (n_samples - gamma_ + 2 * (a - 1)) / (jnp.sum((t - Phi @ mn)**2) + 2 * b)\n",
    "    \n",
    "    return alpha_new, beta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting prerequisites in order\n",
    "n_samples = dt.shape[0]\n",
    "init_vals = (1, 1 / jnp.var(dt))\n",
    "prior_params = (n_samples/2, 1/(n_samples/2 * 1e-4))\n",
    "\n",
    "theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "gram = theta_normed.T @ theta_normed\n",
    "l = jnp.linalg.eigvalsh(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = lambda z: bayes_ridge_update(z[0], z[1], lambda_=l, t=dt, Phi=theta_normed, gram=gram, prior_params=prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 ms ± 287 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fwd_solver(update, init_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems to work. Can we jit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_solver_jit = jax.jit(fwd_solver, static_argnums=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 ms ± 4.77 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fwd_solver_jit(update, init_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wooosh. Now we put it in a nice function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_ridge(dt, theta):\n",
    "    # Getting prerequisites in order\n",
    "    n_samples = dt.shape[0]\n",
    "    init_vals = (1, 1 / jnp.var(dt))\n",
    "    prior_params = (n_samples/2, 1/(n_samples/2 * 1e-4))\n",
    "\n",
    "    theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "    gram = theta_normed.T @ theta_normed\n",
    "    l = jnp.linalg.eigvalsh(gram)\n",
    "    \n",
    "    update = lambda z: bayes_ridge_update(z[0], z[1], lambda_=l, t=dt, Phi=theta_normed, gram=gram, prior_params=prior_params)\n",
    "    return fwd_solver(update, init_vals)\n",
    "\n",
    "bayesian_ridge_jit = jax.jit(bayesian_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 ms ± 848 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bayesian_ridge(dt, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 ms ± 3.64 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bayesian_ridge_jit(dt, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we clean up the code a bit and bring it more in line with the jax implicit layers code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init, tol=1e-3):\n",
    "    def cond_fun(carry):\n",
    "        z_prev, z = carry\n",
    "        return jnp.linalg.norm(z_prev[0] - z[0]) > tol\n",
    "\n",
    "    def body_fun(carry):\n",
    "        _, z = carry\n",
    "        return z, f(z)\n",
    "\n",
    "    init_carry = (z_init, f(z_init))\n",
    "    _, z_star = lax.while_loop(cond_fun, body_fun, init_carry)\n",
    "    return z_star\n",
    "\n",
    "@jax.jit\n",
    "def bayes_ridge_update(params, lambda_, t, Phi, prior_params):\n",
    "    alpha_old, beta_old, _ = params\n",
    "    a, b = prior_params\n",
    "    \n",
    "    n_samples = Phi.shape[0]\n",
    "    n_terms = Phi.shape[1]\n",
    "    \n",
    "    gamma_ = jnp.sum((beta_old * lambda_) / (alpha_old + beta_old * lambda_))\n",
    "    S = jnp.linalg.inv(beta_old * Phi.T @ Phi + alpha_old * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_old * S @ Phi.T @ t\n",
    "    \n",
    "    alpha = gamma_ / jnp.sum(mn**2)\n",
    "    beta = (n_samples - gamma_ + 2 * (a - 1)) / (jnp.sum((t - Phi @ mn)**2) + 2 * b)\n",
    "    \n",
    "    return alpha, beta, mn\n",
    "\n",
    "@jax.jit\n",
    "def bayesian_ridge(params, inputs, tol=1e-3):\n",
    "    # Unpacking inputs\n",
    "    prior_params = params\n",
    "    dt, theta = inputs\n",
    "    \n",
    "    # preparing some useful \n",
    "    init_vals = (1, 1 / jnp.var(dt), jnp.zeros((theta.shape[1], 1)))\n",
    "    theta_normed = theta / jnp.linalg.norm(theta, axis=0)\n",
    "    eigvals = jnp.linalg.eigvalsh(theta_normed.T @ theta_normed) # do we really need both phi and gram?\n",
    "    \n",
    "    # Running\n",
    "    update = partial(bayes_ridge_update, t=dt, Phi=theta_normed, lambda_=eigvals, prior_params=prior_params)\n",
    "    alpha_, beta_, mn = fwd_solver(update, init_vals, tol=tol)\n",
    "    mn = mn / jnp.linalg.norm(theta, axis=0)[:, None] # dimensionalizing again\n",
    "    return alpha_, beta_, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = dt.shape[0]\n",
    "prior_params = ((n_samples/2, 1/(n_samples/2 * 1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8 ms ± 130 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bayesian_ridge(prior_params, (dt, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(0.1628958, dtype=float32),\n",
       " DeviceArray(199.29915, dtype=float32),\n",
       " DeviceArray([[ 4.7251882e-04],\n",
       "              [-1.8976321e-02],\n",
       "              [ 9.8508134e-02],\n",
       "              [ 4.7280577e-05],\n",
       "              [-4.0016812e-03],\n",
       "              [-9.0126008e-01],\n",
       "              [ 5.3995108e-04],\n",
       "              [ 6.2670169e-04],\n",
       "              [ 4.3693967e-03],\n",
       "              [-9.1061093e-02],\n",
       "              [ 7.6659984e-04],\n",
       "              [-5.9627282e-04]], dtype=float32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge(prior_params, (dt, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_solver(f, z_init, tol=1e-3):\n",
    "    def cond_fun(carry):\n",
    "        z_prev, z = carry\n",
    "        return jnp.linalg.norm(z_prev[0] - z[0]) > tol\n",
    "\n",
    "    def body_fun(carry):\n",
    "        _, z = carry\n",
    "        return z, f(z)\n",
    "\n",
    "    init_carry = (z_init, f(z_init))\n",
    "    _, z_star = lax.while_loop(cond_fun, body_fun, init_carry)\n",
    "    return z_star\n",
    "\n",
    "def bayes_ridge_update(params, t, Phi, prior_params):\n",
    "    Phi_normed = Phi / jnp.linalg.norm(theta, axis=0)\n",
    "    eigvals = jnp.linalg.eigvalsh(Phi_normed.T @ Phi_normed) # do we really need both phi and gram?\n",
    "    \n",
    "    alpha_old, beta_old = params\n",
    "    a, b = prior_params\n",
    "    \n",
    "    n_samples = Phi_normed.shape[0]\n",
    "    n_terms = Phi_normed.shape[1]\n",
    "    \n",
    "    gamma_ = jnp.sum((beta_old * eigvals) / (alpha_old + beta_old * eigvals))\n",
    "    S = jnp.linalg.inv(beta_old * Phi_normed.T @ Phi_normed + alpha_old * jnp.eye(n_terms)) # Change to QR?\n",
    "    mn = beta_old * S @ Phi_normed.T @ t\n",
    "    \n",
    "    alpha = gamma_ / jnp.sum(mn**2)\n",
    "    beta = (n_samples - gamma_ + 2 * (a - 1)) / (jnp.sum((t - Phi_normed @ mn)**2) + 2 * b)\n",
    "    \n",
    "    return jnp.ones((1, )) * alpha,  jnp.ones((1, )) * beta\n",
    "\n",
    "@partial(jax.custom_vjp, nondiff_argnums=(0, ))\n",
    "def bayesian_ridge(prior_params, inputs):\n",
    "    # Unpacking inputs\n",
    "    dt, theta = inputs\n",
    "    \n",
    "    # preparing some useful \n",
    "    init_vals = (jnp.ones((1, )), jnp.ones((1, )) / jnp.var(dt))\n",
    "    \n",
    "    # Running\n",
    "    update = partial(bayes_ridge_update, t=dt, Phi=theta, prior_params=prior_params)\n",
    "    z_star = fwd_solver(update, init_vals, tol=1e-3)\n",
    "    return z_star\n",
    "\n",
    "def bayesian_ridge_fwd(prior_params, inputs):\n",
    "    # Unpacking inputs\n",
    "    dt, theta = inputs\n",
    "    \n",
    "    # preparing some useful \n",
    "    init_vals = (jnp.ones((1, )), jnp.ones((1, )) / jnp.var(dt))\n",
    "    \n",
    "    # Running\n",
    "    update = partial(bayes_ridge_update, t=dt, Phi=theta, prior_params=prior_params)\n",
    "    z_star = fwd_solver(update, init_vals, tol=1e-3)\n",
    "    return z_star, (dt, theta, z_star)\n",
    "\n",
    "def bayesian_ridge_bwd(prior_params, res, z_star_bar):\n",
    "    dt, theta, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda dt, Phi: bayes_ridge_update(params=z_star, t=dt, Phi=Phi, prior_params=prior_params), dt, theta)\n",
    "    _, vjp_z = jax.vjp(lambda z: bayes_ridge_update(params=z, t=dt, Phi=theta, prior_params=prior_params), z_star)\n",
    "    return vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar,\n",
    "                      z_init=(jnp.zeros((1,)), jnp.zeros((1, )))))\n",
    "\n",
    "bayesian_ridge.defvjp(bayesian_ridge_fwd, bayesian_ridge_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_ridge_jit = jax.jit(bayesian_ridge, static_argnums=0)\n",
    "\n",
    "n_samples = dt.shape[0]\n",
    "prior_params = ((jnp.ones((1, )) * n_samples/2, jnp.ones((1, )) /(n_samples/2 * 1e-4)))\n",
    "inputs = (dt, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([1000.], dtype=float32), DeviceArray([10.], dtype=float32))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 ms ± 150 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bayesian_ridge_jit(prior_params, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([0.1629698], dtype=float32),\n",
       " DeviceArray([199.29936], dtype=float32))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_jit(prior_params, (dt, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda inputs: bayesian_ridge_jit(prior_params, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([0.1629698], dtype=float32),\n",
       " DeviceArray([199.29936], dtype=float32))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tree structure of cotangent input PyTreeDef(tuple, [*,*,*,*]), does not match structure of primal output PyTreeDef(tuple, [*,*])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-9b0437356955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(cotangent_dtypes, io_tree, fun, py_args)\u001b[0m\n\u001b[1;32m   1790\u001b[0m              \"with dtype {}.\")\n\u001b[1;32m   1791\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_tangent_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m   \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36munbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_consts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mdummy_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mUndefinedPrimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0marg_cts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstantiate_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_cts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mcts_in_avals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutvars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mcall_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_call_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         cts_out = get_primitive_transpose(eqn.primitive)(\n\u001b[0m\u001b[1;32m    225\u001b[0m             params, call_jaxpr, invals, cts_in, cts_in_avals)\n\u001b[1;32m    226\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mcall_transpose\u001b[0;34m(primitive, params, call_jaxpr, args, ct, _)\u001b[0m\n\u001b[1;32m    550\u001b[0m     new_params = update_params(new_params, map(is_undefined_primal, args),\n\u001b[1;32m    551\u001b[0m                                [type(x) is not Zero for x in ct])\n\u001b[0;32m--> 552\u001b[0;31m   \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0mprimitive_transposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_p\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_transpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1218\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_new_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_xla_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrappedFun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonated_invars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m   compiled_fun = _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0m\u001b[1;32m    570\u001b[0m                                *unsafe_map(arg_spec, args))\n\u001b[1;32m    571\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_stores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0mabstract_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momnistaging_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstract_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedTracerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encountered an unexpected tracer.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_final\u001b[0;34m(fun, in_avals)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_sourceinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicJaxprTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0min_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    225\u001b[0m             params, call_jaxpr, invals, cts_in, cts_in_avals)\n\u001b[1;32m    226\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         cts_out = get_primitive_transpose(eqn.primitive)(cts_in, *invals,\n\u001b[0m\u001b[1;32m    228\u001b[0m                                                          **eqn.params)\n\u001b[1;32m    229\u001b[0m     \u001b[0mcts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mZero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvars\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcts_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mZero\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcts_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36m_custom_lin_transpose\u001b[0;34m(cts_out, num_res, bwd, avals_out, *invals)\u001b[0m\n\u001b[1;32m    685\u001b[0m   \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0mcts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstantiate_zeros_aval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavals_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m   \u001b[0mcts_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcts_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_res\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0mprimitive_transposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustom_lin_p\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_custom_lin_transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-d564e1cb170d>\u001b[0m in \u001b[0;36mbayesian_ridge_bwd\u001b[0;34m(prior_params, res, z_star_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbayes_ridge_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbayes_ridge_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     return vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar,\n\u001b[0m\u001b[1;32m     63\u001b[0m                       z_init=(jnp.zeros((1,)), jnp.zeros((1, )))))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-d564e1cb170d>\u001b[0m in \u001b[0;36mfwd_solver\u001b[0;34m(f, z_init, tol)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minit_carry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_carry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond_fun, body_fun, init_val)\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;31m# To do this, we compute the jaxpr in two passes: first with the raw inputs, and if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0;31m# necessary, a second time with modified init values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0minit_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m   \u001b[0mnew_init_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_weak_typed_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_jaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mchanged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36m_create_jaxpr\u001b[0;34m(init_val)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0minit_avals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_abstractify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mcond_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_consts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_initial_style_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mbody_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_consts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_initial_style_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtreedef_is_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_jaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_avals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cond_fun must return a boolean scalar, but got pytree {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36m_initial_style_jaxpr\u001b[0;34m(fun, in_tree, in_avals)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_initial_style_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_initial_style_open_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0mclosed_jaxpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClosedJaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_constvars_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mclosed_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36m_initial_style_open_jaxpr\u001b[0;34m(fun, in_tree, in_avals)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_initial_style_open_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mwrapped_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_sourceinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicJaxprTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0min_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-d564e1cb170d>\u001b[0m in \u001b[0;36mbody_fun\u001b[0;34m(carry)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbody_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minit_carry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-d564e1cb170d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbayes_ridge_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbayes_ridge_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     return vjp_a(fwd_solver(lambda u: vjp_z(u)[0] + z_star_bar,\n\u001b[0m\u001b[1;32m     63\u001b[0m                       z_init=(jnp.zeros((1,)), jnp.zeros((1, )))))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(cotangent_dtypes, io_tree, fun, py_args)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     msg = (\"Tree structure of cotangent input {}, does not match structure of \"\n\u001b[1;32m   1783\u001b[0m            \"primal output {}\")\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree_expected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_dtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msafe_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcotangent_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0mexpected_tangent_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimal_dtype_to_tangent_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tree structure of cotangent input PyTreeDef(tuple, [*,*,*,*]), does not match structure of primal output PyTreeDef(tuple, [*,*])"
     ]
    }
   ],
   "source": [
    "jax.vjp(f, inputs)[1]((jnp.ones((1, )), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
