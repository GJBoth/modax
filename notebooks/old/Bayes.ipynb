{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "from flax import optim\n",
    "from modax.models import DeepmodBayes\n",
    "from modax.training import create_update\n",
    "from modax.losses import *\n",
    "from modax.logging import Logger\n",
    "from modax.data.burgers import burgers\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataset\n",
    "key = random.PRNGKey(42)\n",
    "data_key, network_key = random.split(key)\n",
    "\n",
    "x = jnp.linspace(-3, 4, 100)\n",
    "t = jnp.linspace(0.5, 5.0, 20)\n",
    "\n",
    "t_grid, x_grid = jnp.meshgrid(t, x, indexing=\"ij\")\n",
    "u = burgers(x_grid, t_grid, 0.1, 1.0)\n",
    "\n",
    "X_train = jnp.concatenate([t_grid.reshape(-1, 1), x_grid.reshape(-1, 1)], axis=1)\n",
    "y_train = u.reshape(-1, 1)\n",
    "noise = 0.1\n",
    "y_train += noise * jnp.std(y_train) * jax.random.normal(data_key, shape=y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_mse_bayes, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 2229.12646484375\n",
      "Loss step 1000: -158.70819091796875\n",
      "Loss step 2000: -2143.58642578125\n",
      "Loss step 3000: -4030.03271484375\n",
      "Loss step 4000: -5200.7578125\n",
      "Loss step 5000: -5215.5712890625\n",
      "Loss step 6000: -5222.4560546875\n",
      "Loss step 7000: -5227.3759765625\n",
      "Loss step 8000: -5231.65673828125\n",
      "Loss step 9000: -5234.751953125\n",
      "Loss step 10000: -5236.69091796875\n",
      "Loss step 11000: -5239.78515625\n",
      "Loss step 12000: -5241.943359375\n",
      "Loss step 13000: -5245.2919921875\n",
      "Loss step 14000: -5247.9912109375\n",
      "Loss step 15000: -5250.3349609375\n",
      "Loss step 16000: -5252.9736328125\n",
      "Loss step 17000: -5255.4697265625\n",
      "Loss step 18000: -5257.8818359375\n",
      "Loss step 19000: -5261.3876953125\n",
      "Loss step 20000: -5265.3642578125\n"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 20001\n",
    "logger = Logger(comment='bayes_mse')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74379313]\n",
      " [-3.457244  ]\n",
      " [ 4.345568  ]\n",
      " [ 2.6174734 ]\n",
      " [-0.48236308]\n",
      " [-2.2401612 ]\n",
      " [-1.3107225 ]\n",
      " [-0.21278201]\n",
      " [-0.585649  ]\n",
      " [-1.4443657 ]\n",
      " [ 2.2036114 ]\n",
      " [ 0.2650216 ]]\n"
     ]
    }
   ],
   "source": [
    "prediction, dt, theta, coeffs, s, t = model.apply(optimizer.target, X_train)\n",
    "print(coeffs * jnp.linalg.norm(theta, axis=0, keepdims=True).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_multitask, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 4069.3486328125\n",
      "Loss step 1000: -320.46063232421875\n",
      "Loss step 2000: -4305.1357421875\n",
      "Loss step 3000: -8186.4013671875\n",
      "Loss step 4000: -11310.7470703125\n",
      "Loss step 5000: -13301.9482421875\n",
      "Loss step 6000: -15284.5419921875\n",
      "Loss step 7000: -17221.7890625\n",
      "Loss step 8000: -18867.189453125\n",
      "Loss step 9000: -19273.6796875\n",
      "Loss step 10000: -19144.427734375\n",
      "Loss step 11000: -19401.65625\n",
      "Loss step 12000: -19316.078125\n",
      "Loss step 13000: -19994.478515625\n",
      "Loss step 14000: -19827.263671875\n",
      "Loss step 15000: -19920.486328125\n",
      "Loss step 16000: -19839.603515625\n",
      "Loss step 17000: -19822.388671875\n",
      "Loss step 18000: -20344.5859375\n",
      "Loss step 19000: -20490.58203125\n",
      "Loss step 20000: -20648.03125\n",
      "Loss step 21000: -20795.6015625\n",
      "Loss step 22000: -20240.732421875\n",
      "Loss step 23000: -20435.3984375\n",
      "Loss step 24000: -20258.609375\n",
      "Loss step 25000: -20068.8125\n",
      "Loss step 26000: -20798.93359375\n",
      "Loss step 27000: -20836.216796875\n",
      "Loss step 28000: -20201.09375\n",
      "Loss step 29000: -21198.42578125\n",
      "Loss step 30000: -20881.94921875\n",
      "Loss step 31000: -19995.85546875\n",
      "Loss step 32000: -20460.55078125\n",
      "Loss step 33000: -20069.9140625\n",
      "Loss step 34000: -20975.61328125\n",
      "Loss step 35000: -21103.404296875\n",
      "Loss step 36000: -21059.3984375\n",
      "Loss step 37000: -20391.318359375\n",
      "Loss step 38000: -21421.677734375\n",
      "Loss step 39000: -20707.38671875\n",
      "Loss step 40000: -20429.296875\n",
      "Loss step 41000: -21039.1953125\n",
      "Loss step 42000: -20364.615234375\n",
      "Loss step 43000: -20307.58984375\n",
      "Loss step 44000: -21343.6796875\n",
      "Loss step 45000: -20844.70703125\n",
      "Loss step 46000: -20732.357421875\n",
      "Loss step 47000: -20978.3203125\n",
      "Loss step 48000: -21205.8828125\n",
      "Loss step 49000: -20883.8671875\n",
      "Loss step 50000: -20683.154296875\n",
      "Loss step 51000: -20964.44921875\n",
      "Loss step 52000: -21074.337890625\n",
      "Loss step 53000: -20905.77734375\n",
      "Loss step 54000: -21088.6015625\n",
      "Loss step 55000: -21129.31640625\n",
      "Loss step 56000: -21735.65625\n",
      "Loss step 57000: -21481.81640625\n",
      "Loss step 58000: -20572.06640625\n",
      "Loss step 59000: -21597.962890625\n",
      "Loss step 60000: -21289.97265625\n",
      "Loss step 61000: -20789.353515625\n",
      "Loss step 62000: -21104.6328125\n",
      "Loss step 63000: -21156.32421875\n",
      "Loss step 64000: -20838.453125\n",
      "Loss step 65000: -21896.216796875\n",
      "Loss step 66000: -21645.830078125\n",
      "Loss step 67000: -20994.17578125\n",
      "Loss step 68000: -21658.58203125\n",
      "Loss step 69000: -21219.953125\n",
      "Loss step 70000: -21332.41796875\n",
      "Loss step 71000: -21772.234375\n",
      "Loss step 72000: -21551.3046875\n",
      "Loss step 73000: -21845.92578125\n",
      "Loss step 74000: -21067.037109375\n",
      "Loss step 75000: -21559.3359375\n",
      "Loss step 76000: -21610.12109375\n",
      "Loss step 77000: -21025.955078125\n",
      "Loss step 78000: -21955.078125\n",
      "Loss step 79000: -21939.08203125\n",
      "Loss step 80000: -21691.20703125\n",
      "Loss step 81000: -21426.63671875\n",
      "Loss step 82000: -21085.837890625\n",
      "Loss step 83000: -21895.03125\n",
      "Loss step 84000: -21720.93359375\n",
      "Loss step 85000: -21890.421875\n",
      "Loss step 86000: -21903.564453125\n",
      "Loss step 87000: -21613.7890625\n",
      "Loss step 88000: -21536.943359375\n",
      "Loss step 89000: -21316.927734375\n",
      "Loss step 90000: -21045.33984375\n",
      "Loss step 91000: -21300.14453125\n",
      "Loss step 92000: -21881.171875\n",
      "Loss step 93000: -21353.59375\n",
      "Loss step 94000: -21943.623046875\n",
      "Loss step 95000: -21557.0703125\n",
      "Loss step 96000: -21529.4296875\n",
      "Loss step 97000: -22175.24609375\n",
      "Loss step 98000: -21957.349609375\n",
      "Loss step 99000: -21858.609375\n",
      "Loss step 100000: -21438.2890625\n"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 100001\n",
    "logger = Logger(comment='multitask')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn_bayes, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 12277.25390625\n",
      "Loss step 1000: 5890.10205078125\n",
      "Loss step 2000: -87.94482421875\n",
      "Loss step 3000: -5932.18359375\n",
      "Loss step 4000: -10796.4482421875\n",
      "Loss step 5000: -12891.76171875\n",
      "Loss step 6000: -12894.53515625\n",
      "Loss step 7000: -12895.2587890625\n",
      "Loss step 8000: -12896.43359375\n",
      "Loss step 9000: -12896.591796875\n",
      "Loss step 10000: -12896.32421875\n",
      "Loss step 11000: -12897.212890625\n",
      "Loss step 12000: -12897.65625\n",
      "Loss step 13000: -12897.705078125\n",
      "Loss step 14000: -12897.658203125\n",
      "Loss step 15000: -12897.888671875\n",
      "Loss step 16000: -12897.7646484375\n",
      "Loss step 17000: -12898.365234375\n",
      "Loss step 18000: -12898.048828125\n",
      "Loss step 19000: -12898.619140625\n",
      "Loss step 20000: -12898.447265625\n",
      "Loss step 21000: -12898.5869140625\n",
      "Loss step 22000: -12898.1171875\n",
      "Loss step 23000: -12898.3515625\n",
      "Loss step 24000: -12898.908203125\n",
      "Loss step 25000: -12898.98046875\n",
      "Loss step 26000: -12898.939453125\n",
      "Loss step 27000: -12899.021484375\n",
      "Loss step 28000: -12899.13671875\n",
      "Loss step 29000: -12899.240234375\n",
      "Loss step 30000: -12898.5625\n",
      "Loss step 31000: -12899.318359375\n",
      "Loss step 32000: -12898.884765625\n",
      "Loss step 33000: -12898.65625\n",
      "Loss step 34000: -12899.24609375\n",
      "Loss step 35000: -12898.794921875\n",
      "Loss step 36000: -12899.802734375\n",
      "Loss step 37000: -12899.380859375\n",
      "Loss step 38000: -12899.45703125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-574add4f45a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bayes_pinn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss step {epoch}: {metrics['loss']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreraise_with_filtered_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_under_reraiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36mf_jitted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# probably won't return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m   \u001b[0mf_jitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpp_jitted_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     out_flat = xla.xla_call(\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1218\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_new_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, *args)\u001b[0m\n\u001b[1;32m    570\u001b[0m                                *unsafe_map(arg_spec, args))\n\u001b[1;32m    571\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m  \u001b[0;31m# compiled_fun can only raise in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, *args)\u001b[0m\n\u001b[1;32m    828\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 100001\n",
    "logger = Logger(comment='bayes_pinn')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gamma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b31035824ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gamma' is not defined"
     ]
    }
   ],
   "source": [
    "prior = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "k = n_samples / 2\n",
    "theta = (n_samples / 2 * 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fddc04f2eb0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlNElEQVR4nO3deXhV1b3/8fc3MwTCkBAIhDCKQkBBwlBBRhXUVrAOVetsL9Xa1tZqq23vr3p7e61za1sHqnWoVVu1DlVRKzJVBAyVeQxhCgQCAYEkkOTkrN8fZ8cGOEmAkHOS7M/rec7DyR5OvivR/claaw/mnENERORIMdEuQEREmiYFhIiIhKWAEBGRsBQQIiISlgJCRETCiot2AQ2VlpbmevbsGe0yRESalcWLF+92znWqa5tmHxA9e/YkNzc32mWIiDQrZra5vm00xCQiImEpIEREJCwFhIiIhKWAEBGRsBQQIiISlgJCRETCanIBYWaTzWytmeWZ2V3RrkdExK+a1HUQZhYL/AE4FygAPjOzt51zq6JbWfNQHqiiaH85RQcOsetAOSXlVRysCFBWUcWhyiBmEGMQE2PEmtE6IZaUVvG0TYqjbVI87VvFk56SREpSHGYW7eaISJQ1qYAAhgN5zrl8ADN7BZgCKCBqqAgEWVW4nyVb9rK+qIS8ohI27Cpld0n5Sfn8VvGxdGmXROeURLq2b0XvtGR6pbWhV1oyvdKSaZUQe1K+j4g0bU0tILoBW2t8XQCMOHIjM5sGTAPIysqKTGVRFAw6Vmzfx8zVRXy6oZilBV9QHggCkJIUR9/0Nkw4rRPdO7Smc0oSnVIS6dQmkbZJcbROiKN1QixJ8aGDelXQEXSOqqCjtCLAgUOh1/6Dlewtq6Bofzk79h9ix/5D7Nx3iPl5xfz939sOq6db+1b0z2jLgK7tGJCRQnbXFDI7tFKvQ6SFaWoBEe4Ic9Qj75xz04HpADk5OS3ykXjOOZZv28driwt4f8UOig6UYwand2vH1SN7MLRHB4ZktadLStJxHZhjY/6zbXJiHOlt69+ntDzApuJSNu4uZeOuUtYXlbCqcD8fryki6P30U5LiGJTZjqFZHTizR+iVkhR/vM0WkSakqQVEAdC9xteZwPYo1RIVZRUBXs0t4KWFW1i78wCJcTFM7J/OOf07M+7UdDomJ0S8puTEOLK7tiO7a7vDlh+sqGLNjv2s3L6fVYX7Wbr1C34/K4+gAzPol96WoT07MKxnB87qk0bnlKSI1y4iJ86a0jOpzSwOWAdMBLYBnwFXOedW1rZPTk6Oawk369tXVsmz8zfy/PxN7C2r5Izu7bk8J5Ovnt6Vdq2az1/ipeUBlmz9gtxNe1m8ZS+fb97LgfIAAH3T2zC6bxpn9UllZJ9U9TBEosjMFjvncurapkn1IJxzATP7LvABEAv8qa5waAkqq4K8uGAzv525ni/KKjmnfzo3j+1DTs+O0S7thCQnxjGqbxqj+qYBoTmP1YX7+SRvN59sKOaVz7bw3PxNxBic0b094/qlM7F/OtldUzSHIdLENKkexIlozj2IBfnF/PTvy8nfXcqovqn89IL+Rw3jtDTlgSo+3/IFn+TtZt763Swt+ALnoHNKIhNOS2fCaZ0Z1TeV1glN6m8XkRbnWHoQCogoKKsI8MD7a3lu/iayOrbmnosGMP7UdF/+Bb27pJzZa3fx8ZqdzF23m5LyAAlxMZzVJ5VJ2V04b0BnUtskRrtMkRZHAdEE5RWV8O0/57JhVynXn9WTH08+VX8teyoCQT7btIeZq4v4aPVOtuwpI8ZgZO9Uzh+UwaTszqS31US3yMmggGhiZiwv5I5Xl5IUH8tjVw75cpxejuacY3XhAWasKOTd5YXk7yrFDIb17MgFA7sweWAGXdopLEROlAKiCZk+dwP/994aBndvzxNXn0lGu1bRLqnZcM6xvqiE95YXMmP5DtbuPIAZjOyVytQhXZk8MKNZnekl0hQoIJoA5xy/nrGGp+bmc+HpGTxy+RkkxulWFQ2RV1TCO8u289aS7WzcXUpCXAwTT0tn6pBujDu1k36+IsdAARFlzjl++c5q/vTJRq4Z2YN7Lso+7EpmaRjnHMsK9vHG59t4Z9l2dpdUkJIUx4WnZzB1cDeG9exIjH7eImEpIKLskQ/X8tjHeVx/Vk9+8bUBvjxLKVICVUH+lbebt5Zs54OVOyirqCKrY2suz8nkkqGZGtITOYICIoqen7+JX7y9kiuGdee+rw9SOERQWUWA91fs4NXcAj7NLybGYEy/Tlye051z+ncmIa7JPQZFJOIUEFHySd5urv3TIsafms5T1wzVsFIUbS4u5bXFBbyaW8CO/YfomJzAxUO6cXlOd07tcgx3KhRpoRQQUbBpdylT/vAJXVKSeP07Z9EmUdc4NAVVQcfc9bt4NXcr/1y1k8oqxxnd2/PNEVl87fSuesaF+I4CIsIqAkEueWI+W/eW8fato8lKbR3tkiSM4pJy3lyynZcXbSGvqISUpDguHdqdb47Mok+nNtEuTyQiFBARdt+M1Tw1J5+nrhnKpOwu0S5H6uGcY+HGPby4YDMfrNxBZZXjrD6pXD2yB+cO6Ex8rOYqpOVqdndzbc4W5hczfW4+Vw7PUjg0E2bGyN6pjOydyq4D5fwtdysvLdzCd/7yb9LbJnLFsO5cOSJLZ0CJb6kHcRKUB6o4/7fzqKwK8sEPxujeSs1YVdAxe20RLy7YzOx1uzDg3AGduXFUL4b36qiz0aTFUA8iQp6cnU/+rlKeu2GYwqGZi40xJvbvzMT+ndm6p4y/LNzCy4u28MHKnQzISOGGUT352hldv3zGt0hLph5EA20uLuXcR+YyaWAXfnflkKjVIY3nYEUVb3y+jWc/2cj6ohLS2iRw1YgeXD0yS3eXlWZLk9QR8N2X/s3M1UXMvnOcnrncwjnn+CSvmGc/2cjMNUXExxpfPb0rN47qxaDMlv2gJ2l5NMTUyJYVfME7ywr53oS+CgcfMDNGn5LG6FPS2Li7lOfnb+LV3K288fk2cnp04MbRvZiU3UUXRkqLoR5EA3zz6QWsLjzAnDvH0TZJt5v2o/2HKnk1t4Dn5m9k656DZHVszbfO7sVlQ7vr4jtp0o6lB6ETvU9Q7qY9fJJXzHfG9VE4+FhKUjw3je7F7DvG8+TVZ5LaJoH/99ZKzvr1TB755zqKS8qjXaLICdMQ0wl6cs4GOrSO56oRWdEuRZqA2Bhj8sAMJmV3IXfzXp6ak89jM9fz1JwNXDo0k2+d3ZteacnRLlPkuCggTsC6nQf4aHURt008Rae1ymHMjGE9OzKsZ0fyikp4el4+r+YW8NKiLUwa0IX/GtOboT06RLtMkWOio9sJeGpOPknxMVx3Vs9olyJNWN/0Nvz6ktO5/bx+PD9/Ey8u2ML7K3eQ06MD3x7bh4mnpeuBRtKkaQ7iOO0preAfS7dz2dDudExOiHY50gykt03izkmnMf+uCfziawMo3HeI/3ohl/N/O4+3lmwjUBWMdokiYSkgjtPriwuoqApy9cge0S5FmpnkxDhuGNWLOXeO4zffGIzDcdsrS5j4yBxeXrSF8kBVtEsUOYwC4jg453h50RaG9uigh83ICYuLjWHqkG68f9sYpl8zlPat4rn778sZ88Asnp6XT1lFINoligAKiOOyIH8P+btLuWq4zlyShouJMc7L7sKbt47ixZtG0DutDf/77mpG/fpjHpu5nn1lldEuUXxOk9TH4a0l20hOiOWCQRnRLkVakJpXaC/evJfHZ+XxyD/XMX1uPleP7MFNo3vRqW1itMsUH1JAHKOKQJAZK3Zw7oDOukJWGs3QHh145vphrNq+nyfmbGD63A08+8lGrhjWnZvH9dGzKSSiNMR0jOau28W+g5VcNLhrtEsRHxjQNYXfXTmEmT8ax9TB3fjLwi2MfWA2P39zOdu/OBjt8sQnFBDH6O2l22nfOp7RfTtFuxTxkV5pydx/6enMumMclwzN5K+fbWXsg7P42RvL2aagkEamgDgGFYEgH68pYnJ2FxLi9COTyOvesTX3fX0Qs+8cz+U53flb7lbGPTiLu/++nIK9ZdEuT1ooHe2OwaKNeygpD3BO/87RLkV8rlv7Vvzq4kHMuXM8VwzL4vXFBYx7cDZ3/30ZW/coKOTkUkAcg5lrdpIYF8OovmnRLkUEgK7tW/HLqQOZ8+NxXDUii9cXb2P8Q7P5yWvL2FKsoJCTQwFRD+ccH68p4it9UnX2kjQ5Ge1a8T9TQkHxzRFZvLFkG+Mfns2dry5lc3FptMuTZk4BUY/83aVsLi5j4mnp0S5FpFYZ7Vpx75SBzPvxeK4Z2YO3lm5n4sNzuPvvyzSZLSdMAVGPOWt3ATDuVAWENH2dU5K456Js5v14PN8ckcVriwsY/+Bs7nl7JUX7D0W7PGlmGi0gzOweM9tmZku81wU11t1tZnlmttbMJtVYPtTMlnvrHjOzqN8LeUF+MVkdW9O9Y+tolyJyzDqnJHHvlIHMumMcXz+zG39esJkxD87ivvdWs6e0ItrlSTPR2D2IR51zg73XewBmNgC4AsgGJgOPm1n14P4TwDTgFO81uZHrq1Mw6Fi0aQ8jenWMZhkiJyyzQ2t+fcnpzLx9LBcMzGD6vHzOvv9jHvlwLfsO6l5PUrdoDDFNAV5xzpU75zYCecBwM8sAUpxznzrnHPACMDUK9X1p7c4DfFFWycjeqdEsQ6TBeqYl88g3BvPhD8Yw7tR0Hvs4j7Pv/5jff7yeknLdPVbCa+yA+K6ZLTOzP5lZ9XMWuwFba2xT4C3r5r0/cvlRzGyameWaWe6uXbsao24AFuYXAzCit3oQ0jKc0rktf/jmmbz7/dEM79WRhz5cx5gHZvHHufkcrNDzKORwDQoIM/vIzFaEeU0hNFzUBxgMFAIPV+8W5qNcHcuPXujcdOdcjnMup1Onxrv1xcKNe8js0IrMDpp/kJYlu2s7nr5uGG/eOorsrin86r3VjHlwFs/P36QHF8mXGnQ3V+fcOceynZn9EXjH+7IA6F5jdSaw3VueGWZ5VDjnWLRxj85ekhZtcPf2/PmmESzauIeHPlzLL95eyR/n5XP7uf2YMrgbsXpmtq815llMNR+acDGwwnv/NnCFmSWaWS9Ck9GLnHOFwAEzG+mdvXQt8FZj1Vefgr0HKS6tYEhW+2iVIBIxw3t15K/TRvLCjcNp3zqe2/+2lAt+O4+PVu0kNCUoftSYz4N4wMwGExom2gR8G8A5t9LM/gasAgLArc656j7tLcBzQCtghveKimUF+wA4I7N9tEoQiSgzY0y/Tozum8Z7Kwp5+MN1fOuFXIb26MBPJp/GcJ3N5zvW3P86yMnJcbm5uSf9c+97bzXPfrKJFfdO0h1cxZcqq4K8mlvAb2euY+f+csaf2ok7J53GgK4p0S5NTgIzW+ycy6lrGx35arG04Av6Z7RVOIhvxcfGcNWILGbfMZ67zj+NxZv3cuHv5nHbK5/rPk8+oaNfGMGgY8W2/Zyu4SURWiXEcvPYPsz78QRuGduHD1buYOLDc/jvN1dQdEC372jJFBBhbCwupaQ8wKDMdtEuRaTJaNc6nh9PPo25d47niuHdeXlR6DGoD32wlv2HdFV2S6SACGPdjgMADMjQWKvIkdJTkvjfqYP46PaxnDugM7+flceYB2Yxfe4GDlXqGoqWRAERxtqdBzCDvultol2KSJPVMy2Zx64cwjvfG80Zme35v/fWMOGh2by+uIBgsHmf/CIhCogw1u08QM/UZJLi9YAgkfoM7NaO528czkv/NYLUNon86NWlXPi7fzFvfePdBkciQwERxtodB+jXWb0HkeNxVp803rp1FI9dOYQDhyq55plFXPPMQlZt3x/t0uQEKSCOcKiyik3FZZzauW20SxFpdmJijIvO6MrMH43l5xf2Z1nBPi783Txu/9sStuvJds2OAuII+btKqQo6+nVRQIicqMS4WL51dm/m3jmeaWN6886yQsY9NJtfz1ij51A0IwqII6wvCp3B1E89CJEGa9c6nrvP78+sO8bx1dMzeGruBsY+OItn/rVRd41tBhQQR9i4uxQzyNIjRkVOmm7tW/HI5YP5x3dHM7BrO375zirOeWQO/1i6XWc8NWEKiCNsKS4jIyVJZzCJNIKB3drx4rdG8MKNw0lOiON7L3/OxY9/wgLv4VzStCggjrCpuJQeqcnRLkOkRRvTrxPvfv9sHrrsDIoOlHPF9AXc9NxnrN95INqlSQ0KiCNs2VNGj1QNL4k0ttgY49Khmcy6Yxw/mXwaizbuYfJv5/Hfb66guKQ82uUJCojDlJQH2F1SoR6ESAQlxcdyy7g+zPnxeK4ekcVLi7Yw7sHZPDVHt+6INgVEDdW3MFYPQiTyOiYncO+UgXzwg7MZ3qsj981Yw7mPzuHdZYV6ql2UKCBq2FxcBiggRKKpb3pbnrl+GC/eNILkhDhufenfXPrkp3y+ZW+0S/MdBUQN/wkIDTGJRNvoU9J49/tnc/8lg9iyp4yLH5/P91/+nIK9ZdEuzTcUEDVs2VNGx+QE2iQ25qO6ReRYxcYY3xiWxaw7xvG9CX35YOUOJjw8hwfeX8MBPYOi0Skgaijcd5Cu7ZOiXYaIHKFNYhw/Ou/U0BXZgzJ4fPYGxj80m5cWbiFQFYx2eS2WAqKGHfsO0SWlVbTLEJFadG3fike+MZi3vzuK3mlt+Okby7nwsX8xd51uLd4YFBA1FO47pB6ESDNwemZ7/vrtkTx59ZkcClRx7Z8Wcf2zi3Sh3UmmgPCUVQTYd7CSLu0UECLNgZkxeWAGH/5wDD+/sD+LN+9l8m/n8fM3l7OntCLa5bUICghP4b5DAHRtpyEmkeak+tbic+4czzUje/Dyoq2M8+4YW6n5iQZRQHgKvwgFhHoQIs1Tx+QE7rkom/dvO5vBWR345TurmPybucxaWxTt0potBYSncF/oaVfqQYg0b6d0bsvzNwzjT9fnEHRww7Ofcf2zi8grKol2ac2OAsKzwxtiSk9JjHIlItJQZsaE0zrzwQ+8+YlNe5n8m7n8zz9W6Yl2x0EB4dlVUk67VvF6DoRIC5IQF8O3zu7NrDvHcVlOd56dv5HxD83mxQWbqdKDiuqlgPAUl1SQ2iYh2mWISCNIa5PIfV8fxDvfG80p6W34+ZsruPCxeczP2x3t0po0BYRnV0k5aW00vCTSkmV3bccr00byxDfPpKQ8wFVPL+Tbf85lS7Hu7xSOAsJTXFJOmnoQIi2emXH+oAw+un0sd046lXnrd3POI3O4//01lJQHol1ek6KA8OwuqVAPQsRHkuJjuXV839D9nc7I4Anv/k6v5m4lqPkJQAEBQEUgyL6DlaQmKyBE/KZzShKPXD6YN75zFpkdWnHna8uY+vgnLN68J9qlRZ0CAr68LD+trYaYRPxqSFYHXr/5LH7zjcHs3H+IS574lNte+fzLU+D9SAEB7PYekK4hJhF/i4kxpg7p9uXzJ2as2MGEh2fz+Ow8ygP+ez62AoKaAaEehIhA64TQ8yc++uFYRvVN44H31zL5N/OYtcZft+1QQBCaoAb1IETkcFmprfnjtTk8f+NwzOCG5z7jxuc+Y9Pu0miXFhENCggzu8zMVppZ0Mxyjlh3t5nlmdlaM5tUY/lQM1vurXvMzMxbnmhmf/WWLzSzng2p7Xh8URYKiPat1YMQkaON7deJ928bw08vOI2F+cWc9+hcHnh/DaUt/LTYhvYgVgBfB+bWXGhmA4ArgGxgMvC4mVXfw+IJYBpwivea7C2/CdjrnOsLPArc38Dajtm+g5WYQVs9i1pEapEQF8O0MX2+PC328dkbmPjwHN5asg3nWuZpsQ0KCOfcaufc2jCrpgCvOOfKnXMbgTxguJllACnOuU9d6Cf6AjC1xj7Pe+9fAyZW9y4a276DlaQkxRMTE5FvJyLNWLp3Wuzrt3yFtLYJ3PbKEr4xfQGrtu+PdmknXWPNQXQDttb4usBb1s17f+Tyw/ZxzgWAfUBquA83s2lmlmtmubt2NfxZtPsOVtKuVXyDP0dE/GNoj468deto/u/iQazfeYCv/m4e//3mii+HrFuCegPCzD4ysxVhXlPq2i3MMlfH8rr2OXqhc9OdcznOuZxOnTrV3YBjsF8BISInIDbGuGpEFrPvCD3N7i8LNzP+odn8ZWHLuFtsvYPuzrlzTuBzC4DuNb7OBLZ7yzPDLK+5T4GZxQHtgIhcyqgehIg0RLvW8dw7ZSBXDM/inrdX8rM3VvDSwi3ce1E2OT07Rru8E9ZYQ0xvA1d4Zyb1IjQZvcg5VwgcMLOR3vzCtcBbNfa5znt/KfCxi9DMz76DlaS00gS1iDRM/4wUXpk2kt9dOYQ9pRVc+uSn/PCvS9i5v3lejd3Q01wvNrMC4CvAu2b2AYBzbiXwN2AV8D5wq3Ou+jLEW4CnCU1cbwBmeMufAVLNLA+4HbirIbUdj30HA+pBiMhJYWZ87YyuzPzRWG4d34d3lxUy4aHZPDlnAxWBYLTLOy7W3E/PysnJcbm5uQ36jH4/n8ENo3py9/n9T1JVIiIhm4tL+eU7q/hodRG905L5xUXZjO3X8LnThjKzxc65nLq28f2V1Icqq6gIBNWDEJFG0SM1maevG8azNwwj6BzX/WkRt7y4mG1fHIx2afXyfUBUP8BcASEijWn8qel88MMx3HFeP2atLeKch+fwh1lN+yaACggvIFKSFBAi0rgS42L57oRT+Oj2sYzpl8aDH4RuAjhnXcOv52oMvg+I/epBiEiEZXZozVPX5PDcDcNwTXjYyfcBoSEmEYmWcU182Mn3AVH9kPK2SboOQkQir7Zhp7lNYNjJ9wFRWh5K6mTdyVVEoujIYadrm8Cwk+8Doqwi1INonRBbz5YiIo2vKQ07+T4gqoeYWieoByEiTUO4YafzozDs5PuAKKuoolV8LLF6FoSINDE1h52CURh28n1AlJYHSE7U8JKINF3RGnbyfUCUVVRpeElEmrxww07P/Gtjo35P3x8ZS8sDmqAWkWajethp7rpdDO3RoVG/lwKiIkAbneIqIs3MmAjcEdb3Q0yl5VW0VkCIiBzF9wFRVhEgWUNMIiJH8X1AlJZrklpEJBzfB0RZhU5zFREJx/cBcbAydKGciIgcztcB4ZzjUGWQxDhf/xhERMLy9ZGxoioIQKJ6ECIiR/F1QByqDAVEkgJCROQovg6I6vuYaIhJRORovj4ylqsHISJSK18HxKFK9SBERGrj6yNjeUA9CBGR2vg6INSDEBGpna+PjDqLSUSkdr4OiOqzmJLiff1jEBEJy9dHxuoeRGKcehAiIkfyeUCoByEiUhtfHxmrz2JSD0JE5Gi+Dgj1IEREaufrI6OugxARqZ2vA6K6B5EQ6+sfg4hIWL4+Mh4KVJEQG0NMjEW7FBGRJsfXAVEZcCToKmoRkbAadHQ0s8vMbKWZBc0sp8bynmZ20MyWeK8na6wbambLzSzPzB4zM/OWJ5rZX73lC82sZ0NqOxaBYJC4WPUeRETCaeifzyuArwNzw6zb4Jwb7L1urrH8CWAacIr3muwtvwnY65zrCzwK3N/A2upVWeWIi1EPQkQknAYdHZ1zq51za491ezPLAFKcc5865xzwAjDVWz0FeN57/xowsbp30VgCVUHi1YMQEQmrMf987mVmn5vZHDM721vWDSiosU2Bt6x63VYA51wA2AekhvtgM5tmZrlmlrtr164TLjAQdBpiEhGpRVx9G5jZR0CXMKt+5px7q5bdCoEs51yxmQ0F3jSzbCDc0dhVf6s61h2+0LnpwHSAnJycsNsci8qqIPEaYhIRCavegHDOnXO8H+qcKwfKvfeLzWwD0I9QjyGzxqaZwHbvfQHQHSgwszigHbDneL/38QhUqQchIlKbRvnz2cw6mVms9743ocnofOdcIXDAzEZ68wvXAtW9kLeB67z3lwIfe/MUjSYQDGqSWkSkFg09zfViMysAvgK8a2YfeKvGAMvMbCmhCeebnXPVvYFbgKeBPGADMMNb/gyQamZ5wO3AXQ2p7VhUVjlNUouI1KLeIaa6OOfeAN4Is/x14PVa9skFBoZZfgi4rCH1HK/QdRDqQYiIhOPro2PoOgj1IEREwvF1QISug/D1j0BEpFa+PjrqOggRkdr5OiB0qw0Rkdr5+uioW22IiNTO3wERdDqLSUSkFr4+OlZWBXUWk4hILXwdEAGd5ioiUit/B4QulBMRqZWvj4661YaISO18HRBVQZ3mKiJSG18fHSt1mquISK18HRC6klpEpHa+DQjnnIaYRETq4NujY2VV6FlEGmISEQnPtwERCAYBdJqriEgtfHt0rO5B6EI5EZHwfBsQgapQD0LPgxARCc+3R8dA0OtBaA5CRCQs3wZEZXUPQmcxiYiE5dujY6BKPQgRkbr4NyC8IaZYTVKLiITl24AIOgWEiEhdFBCmgBARCce3AVHlDTGZAkJEJCzfBoTXgdAQk4hILXwbENU9COWDiEh4vg2I6jmIGCWEiEhYCgjNQYiIhOXjgAj9q7OYRETC821AaA5CRKRuvg2I6iEmneYqIhKebwNCp7mKiNTNtwGhISYRkbr5NiB0mquISN0UEJqDEBEJy78BEXpekE5zFRGpRYMCwsweNLM1ZrbMzN4ws/Y11t1tZnlmttbMJtVYPtTMlnvrHjPvNCIzSzSzv3rLF5pZz4bUVp+qL89iaszvIiLSfDW0B/FPYKBz7nRgHXA3gJkNAK4AsoHJwONmFuvt8wQwDTjFe032lt8E7HXO9QUeBe5vYG11cnoehIhInRoUEM65D51zAe/LBUCm934K8Ipzrtw5txHIA4abWQaQ4pz71IWO0C8AU2vs87z3/jVgojXiRQreI6k1ByEiUouTOQdxIzDDe98N2FpjXYG3rJv3/sjlh+3jhc4+IPUk1neY/zxRrrG+g4hI8xZX3wZm9hHQJcyqnznn3vK2+RkQAP5SvVuY7V0dy+vaJ1xN0wgNU5GVlVVr7XXRldQiInWrNyCcc+fUtd7MrgO+Ckx01QP7oZ5B9xqbZQLbveWZYZbX3KfAzOKAdsCeWmqaDkwHyMnJCRsi9dEjR0VE6tbQs5gmAz8BLnLOldVY9TZwhXdmUi9Ck9GLnHOFwAEzG+nNL1wLvFVjn+u895cCH9cInJNOcxAiInWrtwdRj98DicA/vaGaBc65m51zK83sb8AqQkNPtzrnqrx9bgGeA1oRmrOonrd4BvizmeUR6jlc0cDa6vSfK6kb87uIiDRfDQoI75TU2tb9CvhVmOW5wMAwyw8BlzWknuMRDOpKahGRuvj27+eg7uYqIlIn3waErqQWEambbwPC6WZ9IiJ18m1AVM9B6DRXEZHwfBsQVd4chHoQIiLh+TYgnE5zFRGpk28Pj1U6zVVEpE6+DYheaclcOCiDuFgFhIhIOA29krrZOi+7C+dlh7sHoYiIgI97ECIiUjcFhIiIhKWAEBGRsBQQIiISlgJCRETCUkCIiEhYCggREQlLASEiImFZIz72OSLMbBew+QR3TwN2n8RymgO12R/UZn9oSJt7OOc61bVBsw+IhjCzXOdcTrTriCS12R/UZn9o7DZriElERMJSQIiISFh+D4jp0S4gCtRmf1Cb/aFR2+zrOQgREamd33sQIiJSCwWEiIiE1awDwswmm9laM8szs7vCrDcze8xbv8zMzqxvXzPraGb/NLP13r8daqy729t+rZlNavwWHi2SbTazVDObZWYlZvb7yLTwaBFu87lmttjMlnv/TohMK49qUyTbPNzMlnivpWZ2cWRaeVSbIvr/s7c+y/vv+47GbV14Ef499zSzgzV+10/WW6Bzrlm+gFhgA9AbSACWAgOO2OYCYAZgwEhgYX37Ag8Ad3nv7wLu994P8LZLBHp5+8e28DYnA6OBm4Hf++T3PATo6r0fCGzzQZtbA3He+wygqPrrltrmGp/5OvAqcIcPfs89gRXHU2Nz7kEMB/Kcc/nOuQrgFWDKEdtMAV5wIQuA9maWUc++U4DnvffPA1NrLH/FOVfunNsI5HmfE0kRbbNzrtQ59y/gUGM2qh6RbvPnzrnt3vKVQJKZJTZS22oT6TaXOecC3vIkIBpnrkT6/2fMbCqQT+j3HA0Rb/Pxas4B0Q3YWuPrAm/ZsWxT176dnXOFAN6/6cfx/RpbpNvcFESzzZcAnzvnyk+4+hMT8Tab2QgzWwksB26uERiREtE2m1ky8BPg3pNU/4mIxn/bvczsczObY2Zn11dg3LG0oomyMMuO/Muntm2OZd8T+X6NLdJtbgqi0mYzywbuB847lu1Psoi32Tm3EMg2s/7A82Y2wzkXyZ5jpNt8L/Coc67ELNzuERHpNhcCWc65YjMbCrxpZtnOuf217dCcA6IA6F7j60xg+zFuk1DHvjvNLMM5V+h15YqO4/s1tki3uSmIeJvNLBN4A7jWObfhpLTi+ETt9+ycW21mpYTmX3Ib1IrjE+k2jwAuNbMHgPZA0MwOOecieTJGRNvs9YTLvfeLzWwD0I+6fs8NmWSJ5otQuOUTmjCunqTJPmKbCzl8gmdRffsCD3L4BM8D3vtsDp+kzifyk9QRbXONz7ye6E1SR/r33N7b7hIf/bfdi/9MUvcgdKBJa8ltPuJz7yE6k9SR/j13wjtmEZrc3gZ0rLPGaP1PcJJ+wBcA6wjN5v/MW3YzoTFUvB/qH7z1y4Gcuvb1lqcCM4H13r8da6z7mbf9WuB8n7R5E7AHKCH018yAxm5jNNsM/BwoBZbUeKW38DZfQ2iidgnwb2CqH/7brrHNPUQhIKLwe77E+z0v9X7PX6uvPt1qQ0REwmrOZzGJiEgjUkCIiEhYCggREQlLASEiImEpIEREJCwFhIiIhKWAEBGRsP4/sJNqJfQBf3EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jnp.linspace(0, 5e-4, 1000)\n",
    "p = gamma.logpdf(x, a=n_samples/2, scale = 2/n_samples * 1e-4) \n",
    "plt.plot(x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_mse_bayes_precalc, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-42672513c5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bayes_mse_precalc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss step {epoch}: {metrics['loss']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update' is not defined"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 20001\n",
    "logger = Logger(comment='bayes_mse_precalc')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn_bayes_full, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 664014.875\n",
      "Loss step 1000: -11706.9248046875\n",
      "Loss step 2000: -15791.791015625\n",
      "Loss step 3000: -16156.58203125\n",
      "Loss step 4000: -16177.9345703125\n",
      "Loss step 5000: -16187.7900390625\n",
      "Loss step 6000: -16187.6201171875\n",
      "Loss step 7000: -16195.263671875\n",
      "Loss step 8000: -16193.439453125\n",
      "Loss step 9000: -16194.6875\n",
      "Loss step 10000: -16194.677734375\n",
      "Loss step 11000: -16199.6357421875\n",
      "Loss step 12000: -16198.427734375\n",
      "Loss step 13000: -16199.9423828125\n",
      "Loss step 14000: -16196.31640625\n",
      "Loss step 15000: -16197.87109375\n",
      "Loss step 16000: -16201.3017578125\n",
      "Loss step 17000: -16197.625\n",
      "Loss step 18000: -16198.70703125\n",
      "Loss step 19000: -16200.9921875\n",
      "Loss step 20000: -16198.8388671875\n",
      "Loss step 21000: -16201.427734375\n",
      "Loss step 22000: -16201.6787109375\n",
      "Loss step 23000: -16201.4794921875\n",
      "Loss step 24000: -16199.3779296875\n",
      "Loss step 25000: -16201.1435546875\n",
      "Loss step 26000: -16202.154296875\n",
      "Loss step 27000: -16202.8671875\n",
      "Loss step 28000: -16199.453125\n",
      "Loss step 29000: -16199.482421875\n",
      "Loss step 30000: -16199.927734375\n",
      "Loss step 31000: -16199.6787109375\n",
      "Loss step 32000: -16200.986328125\n",
      "Loss step 33000: -16202.294921875\n",
      "Loss step 34000: -16200.662109375\n",
      "Loss step 35000: -16202.720703125\n",
      "Loss step 36000: -16202.6396484375\n",
      "Loss step 37000: -16201.8994140625\n",
      "Loss step 38000: -16201.109375\n",
      "Loss step 39000: -16202.8125\n",
      "Loss step 40000: -16203.380859375\n",
      "Loss step 41000: -16202.642578125\n",
      "Loss step 42000: -16200.1298828125\n",
      "Loss step 43000: -16201.181640625\n",
      "Loss step 44000: -16203.400390625\n",
      "Loss step 45000: -16203.396484375\n",
      "Loss step 46000: -16204.1689453125\n",
      "Loss step 47000: -16201.1240234375\n",
      "Loss step 48000: -16201.9873046875\n",
      "Loss step 49000: -16203.0078125\n",
      "Loss step 50000: -16203.7578125\n"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 50001\n",
    "logger = Logger(comment='precalc')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn_bayes, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 12277.25390625\n",
      "Loss step 1000: 5890.10205078125\n",
      "Loss step 2000: -87.94482421875\n",
      "Loss step 3000: -5932.1767578125\n",
      "Loss step 4000: -10796.4951171875\n",
      "Loss step 5000: -12891.408203125\n",
      "Loss step 6000: -12894.732421875\n",
      "Loss step 7000: -12895.771484375\n",
      "Loss step 8000: -12896.326171875\n",
      "Loss step 9000: -12897.146484375\n",
      "Loss step 10000: -12896.953125\n",
      "Loss step 11000: -12897.4140625\n",
      "Loss step 12000: -12897.69140625\n",
      "Loss step 13000: -12897.4404296875\n",
      "Loss step 14000: -12897.01171875\n",
      "Loss step 15000: -12897.859375\n",
      "Loss step 16000: -12898.0185546875\n",
      "Loss step 17000: -12898.4501953125\n",
      "Loss step 18000: -12898.59765625\n",
      "Loss step 19000: -12898.212890625\n",
      "Loss step 20000: -12898.232421875\n",
      "Loss step 21000: -12898.546875\n",
      "Loss step 22000: -12898.560546875\n",
      "Loss step 23000: -12898.732421875\n",
      "Loss step 24000: -12898.20703125\n",
      "Loss step 25000: -12899.19140625\n",
      "Loss step 26000: -12899.111328125\n",
      "Loss step 27000: -12898.87890625\n",
      "Loss step 28000: -12899.017578125\n",
      "Loss step 29000: -12899.0126953125\n",
      "Loss step 30000: -12898.736328125\n",
      "Loss step 31000: -12899.14453125\n",
      "Loss step 32000: -12898.662109375\n",
      "Loss step 33000: -12899.46875\n",
      "Loss step 34000: -12898.9140625\n",
      "Loss step 35000: -12899.328125\n",
      "Loss step 36000: -12899.4375\n",
      "Loss step 37000: -12899.7783203125\n",
      "Loss step 38000: -12899.52734375\n",
      "Loss step 39000: -12899.3779296875\n",
      "Loss step 40000: -12899.59375\n",
      "Loss step 41000: -12899.37109375\n",
      "Loss step 42000: -12899.3564453125\n",
      "Loss step 43000: -12899.4765625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-781f0a024899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss step {epoch}: {metrics['loss']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreraise_with_filtered_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_under_reraiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36mf_jitted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# probably won't return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m   \u001b[0mf_jitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpp_jitted_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     out_flat = xla.xla_call(\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1218\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_new_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, *args)\u001b[0m\n\u001b[1;32m    570\u001b[0m                                *unsafe_map(arg_spec, args))\n\u001b[1;32m    571\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m  \u001b[0;31m# compiled_fun can only raise in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, *args)\u001b[0m\n\u001b[1;32m    828\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 50001\n",
    "logger = Logger(comment='opt')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model and optimizers\n",
    "model = DeepmodBayes(features=[50, 50, 1])\n",
    "\n",
    "params = model.init(network_key, X_train)\n",
    "optimizer = optim.Adam(learning_rate=2e-3, beta1=0.99, beta2=0.99)\n",
    "optimizer = optimizer.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling train step\n",
    "update = create_update(loss_fn_pinn_bayes_approximate, model=model, x=X_train, y=y_train)\n",
    "_ = update(optimizer)  # triggering compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0: 2171.886962890625\n",
      "Loss step 1000: -5671.0595703125\n",
      "Loss step 2000: -5684.8388671875\n",
      "Loss step 3000: -5687.47900390625\n",
      "Loss step 4000: -5688.6123046875\n",
      "Loss step 5000: -5688.79638671875\n",
      "Loss step 6000: -5690.796875\n",
      "Loss step 7000: -5691.8525390625\n",
      "Loss step 8000: -5692.1611328125\n",
      "Loss step 9000: -5691.193359375\n",
      "Loss step 10000: -5693.21240234375\n",
      "Loss step 11000: -5692.2431640625\n",
      "Loss step 12000: -5692.1748046875\n",
      "Loss step 13000: -5693.20166015625\n",
      "Loss step 14000: -5693.39306640625\n",
      "Loss step 15000: -5694.048828125\n",
      "Loss step 16000: -5693.984375\n",
      "Loss step 17000: -5694.12646484375\n",
      "Loss step 18000: -5693.8603515625\n",
      "Loss step 19000: -5694.3017578125\n",
      "Loss step 20000: -5694.970703125\n"
     ]
    }
   ],
   "source": [
    "# Running to convergence\n",
    "max_epochs = 20001\n",
    "logger = Logger(comment='bayes_approx')\n",
    "for epoch in jnp.arange(max_epochs):\n",
    "    optimizer, metrics = update(optimizer)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss step {epoch}: {metrics['loss']}\")\n",
    "    if epoch % 100 == 0:\n",
    "        logger.write(metrics, epoch)\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
