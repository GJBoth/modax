{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "familiar-festival",
   "metadata": {},
   "source": [
    "In this notebook we try to get a forward solver for the SBL working and explicitly differentiate, and compare with the implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "located-logging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "from jax import numpy as jnp, random\n",
    "import jax\n",
    "\n",
    "from modax.data.kdv import doublesoliton\n",
    "from modax.models import Deepmod\n",
    "from modax.training.utils import create_update\n",
    "from flax import optim\n",
    "from modax.training import train_max_iter\n",
    "from modax.training.losses.utils import precision, normal_LL\n",
    "\n",
    "\n",
    "from forward_solver import fixed_point_solver_explicit, fixed_point_solver_implicit\n",
    "from SBL import SBL\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-marathon",
   "metadata": {},
   "source": [
    "Lets first create some fake input the neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-sarah",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "overall-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(42)\n",
    "x = jnp.linspace(-10, 10, 100)\n",
    "t = jnp.linspace(0.1, 1.0, 10)\n",
    "t_grid, x_grid = jnp.meshgrid(t, x, indexing=\"ij\")\n",
    "u = doublesoliton(x_grid, t_grid, c=[5.0, 2.0], x0=[0.0, -5.0])\n",
    "\n",
    "X = jnp.concatenate([t_grid.reshape(-1, 1), x_grid.reshape(-1, 1)], axis=1)\n",
    "y = u.reshape(-1, 1)\n",
    "y += 0.10 * jnp.std(y) * random.normal(key, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hungarian-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Building model and params\n",
    "model = Deepmod([30, 30, 30, 1])\n",
    "variables = model.init(key, X)\n",
    "\n",
    "prediction, dt, theta, coeffs = model.apply(variables, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "immediate-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = theta.shape\n",
    "prior_params_mse = (0.0, 0.0)\n",
    "tau = precision(y, prediction, *prior_params_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electoral-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_prior = (1e-6, 1e-6)\n",
    "beta_prior = (n_samples / 2, n_samples / (jax.lax.stop_gradient(tau)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-travel",
   "metadata": {},
   "source": [
    "# Bayesian regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-orbit",
   "metadata": {},
   "source": [
    "Let's first do a forward pass wihtout jit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "respected-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    loss, coeffs, prior, metrics= SBL(fixed_point_solver_explicit, \n",
    "                                                        theta, \n",
    "                                                        dt, \n",
    "                                                        prior_init=None, \n",
    "                                                        hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                        tol=1e-4, \n",
    "                                                        max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "recorded-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-234.16995 [[ 2.8810082e-03]\n",
      " [-5.4706748e-06]\n",
      " [ 5.0718643e-02]\n",
      " [-1.0429989e-04]\n",
      " [ 7.3084915e-01]\n",
      " [ 4.2338760e-04]\n",
      " [-2.3527378e-04]\n",
      " [ 5.7718530e-04]\n",
      " [ 2.4089876e-04]\n",
      " [ 5.9699081e-04]\n",
      " [ 5.5704353e-04]\n",
      " [-3.3291994e-04]] [1.2790438e+04 2.7565962e+03 5.8328896e+01 4.3157676e+03 1.4594887e+00\n",
      " 1.0524597e+02 1.9473764e+02 4.4398584e+02 1.3007578e+02 1.2405847e+01\n",
      " 2.1486467e+01 4.7296772e+01 2.1528165e+00] (50, DeviceArray(9.250849e-05, dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(loss, coeffs, prior, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-express",
   "metadata": {},
   "source": [
    "So it works without jit - with jit it doesnt work (yet). Let's first check if we can calculate the derivative w.r.t the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hungarian-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dtheta = jax.grad(lambda X: SBL(fixed_point_solver_explicit, \n",
    "                                    X, \n",
    "                                    dt, \n",
    "                                    prior_init=None, \n",
    "                                    hyper_prior=(alpha_prior, beta_prior), \n",
    "                                    tol=1e-4, \n",
    "                                    max_iter=500)[0])\n",
    "\n",
    "dL_ddt = jax.grad(lambda y: SBL(fixed_point_solver_explicit, \n",
    "                                    theta, \n",
    "                                    y, \n",
    "                                    prior_init=None, \n",
    "                                    hyper_prior=(alpha_prior, beta_prior), \n",
    "                                    tol=1e-4, \n",
    "                                    max_iter=500)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "polar-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    grad_theta_exp = dL_dtheta(theta)\n",
    "    grad_dt_exp = dL_ddt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "american-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_theta_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "respective-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_dt_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "working-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(False, dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_theta_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "equivalent-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(False, dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_dt_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-round",
   "metadata": {},
   "source": [
    "No nan- seems fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-payroll",
   "metadata": {},
   "source": [
    "So its not fast but we're getting results. Now let's run a pass using the implicit diff method and compare the results - they should be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "graphic-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    loss, coeffs, prior, metrics= SBL(fixed_point_solver_implicit, \n",
    "                                        theta, \n",
    "                                        dt, \n",
    "                                        prior_init=None, \n",
    "                                        hyper_prior=(alpha_prior, beta_prior), \n",
    "                                        tol=1e-4, \n",
    "                                        max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "later-swaziland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-234.16995 [[ 2.8810082e-03]\n",
      " [-5.4706748e-06]\n",
      " [ 5.0718643e-02]\n",
      " [-1.0429989e-04]\n",
      " [ 7.3084915e-01]\n",
      " [ 4.2338760e-04]\n",
      " [-2.3527378e-04]\n",
      " [ 5.7718530e-04]\n",
      " [ 2.4089876e-04]\n",
      " [ 5.9699081e-04]\n",
      " [ 5.5704353e-04]\n",
      " [-3.3291994e-04]] [1.2790438e+04 2.7565962e+03 5.8328896e+01 4.3157676e+03 1.4594887e+00\n",
      " 1.0524597e+02 1.9473764e+02 4.4398584e+02 1.3007578e+02 1.2405847e+01\n",
      " 2.1486467e+01 4.7296772e+01 2.1528165e+00] (50, DeviceArray(9.250849e-05, dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(loss, coeffs, prior, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-postage",
   "metadata": {},
   "source": [
    "Forward pass is the same as it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "danish-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dtheta_imp = jax.grad(lambda X: SBL(fixed_point_solver_implicit, \n",
    "                                                            X, \n",
    "                                                            dt, \n",
    "                                                            prior_init=None, \n",
    "                                                            hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                            tol=1e-4, \n",
    "                                                            max_iter=500)[0])\n",
    "\n",
    "dL_ddt_imp = jax.grad(lambda y: SBL(fixed_point_solver_implicit, \n",
    "                                                            theta, \n",
    "                                                            y, \n",
    "                                                            prior_init=None, \n",
    "                                                            hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                            tol=1e-4, \n",
    "                                                            max_iter=500)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adaptive-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    grad_theta_imp = dL_dtheta_imp(theta)\n",
    "    grad_dt_imp = dL_ddt_imp(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-taste",
   "metadata": {},
   "source": [
    "That worked - now let's check if they're similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "enabling-reaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(True, dtype=bool)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_theta_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "functional-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(nan, dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(jnp.abs(grad_theta_exp - grad_theta_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afraid-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(nan, dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(jnp.abs(grad_dt_exp - grad_dt_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-bradley",
   "metadata": {},
   "source": [
    "Okay so as usual the implicit method gives a nan. The best approach for now is to get the jit version of the explicit method working and see that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-pizza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
