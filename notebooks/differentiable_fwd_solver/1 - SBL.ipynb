{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaging-export",
   "metadata": {},
   "source": [
    "In this notebook we try to get a forward solver for the SBL working and explicitly differentiate, and compare with the implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "traditional-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "from jax import numpy as jnp, random\n",
    "import jax\n",
    "\n",
    "from modax.data.kdv import doublesoliton\n",
    "from modax.models import Deepmod\n",
    "from modax.training.utils import create_update\n",
    "from flax import optim\n",
    "from modax.training import train_max_iter\n",
    "from modax.training.losses.utils import precision, normal_LL\n",
    "\n",
    "\n",
    "from forward_solver import fixed_point_solver_explicit, fixed_point_solver_implicit\n",
    "from SBL import SBL\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-payment",
   "metadata": {},
   "source": [
    "Lets first create some fake input the neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-payday",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "frank-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(42)\n",
    "x = jnp.linspace(-10, 10, 100)\n",
    "t = jnp.linspace(0.1, 1.0, 10)\n",
    "t_grid, x_grid = jnp.meshgrid(t, x, indexing=\"ij\")\n",
    "u = doublesoliton(x_grid, t_grid, c=[5.0, 2.0], x0=[0.0, -5.0])\n",
    "\n",
    "X = jnp.concatenate([t_grid.reshape(-1, 1), x_grid.reshape(-1, 1)], axis=1)\n",
    "y = u.reshape(-1, 1)\n",
    "y += 0.10 * jnp.std(y) * random.normal(key, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proprietary-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Building model and params\n",
    "model = Deepmod([30, 30, 30, 1])\n",
    "variables = model.init(key, X)\n",
    "\n",
    "prediction, dt, theta, coeffs = model.apply(variables, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "consolidated-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = theta.shape\n",
    "prior_params_mse = (0.0, 0.0)\n",
    "tau = precision(y, prediction, *prior_params_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_prior = (1e-6, 1e-6)\n",
    "beta_prior = (n_samples / 2, n_samples / (jax.lax.stop_gradient(tau)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-tackle",
   "metadata": {},
   "source": [
    "# SBL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-stroke",
   "metadata": {},
   "source": [
    "Let's first do a forward pass wihtout jit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adequate-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    loss, coeffs, prior, metrics= SBL(fixed_point_solver_explicit, \n",
    "                                                        theta, \n",
    "                                                        dt, \n",
    "                                                        prior_init=None, \n",
    "                                                        hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                        tol=1e-4, \n",
    "                                                        max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thick-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-234.16673 [[ 2.8835083e-03]\n",
      " [-7.3347251e-06]\n",
      " [ 5.0495405e-02]\n",
      " [-5.9845635e-05]\n",
      " [ 7.3062313e-01]\n",
      " [ 4.2678340e-04]\n",
      " [-2.3846346e-04]\n",
      " [ 5.8384158e-04]\n",
      " [ 2.2641293e-04]\n",
      " [ 5.9847737e-04]\n",
      " [ 5.5580394e-04]\n",
      " [-3.4260462e-04]] [1.2780464e+04 1.9792905e+03 5.8624344e+01 7.6146699e+03 1.4603415e+00\n",
      " 1.0457022e+02 1.9202785e+02 4.3865234e+02 1.3856334e+02 1.2384184e+01\n",
      " 2.1545572e+01 4.6018299e+01 2.1528099e+00] (300, 0)\n"
     ]
    }
   ],
   "source": [
    "print(loss, coeffs, prior, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-multimedia",
   "metadata": {},
   "source": [
    "So it works without jit - with jit it doesnt work (yet). Let's first check if we can calculate the derivative w.r.t the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hidden-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dtheta = jax.grad(lambda X: SBL(fixed_point_solver_explicit, \n",
    "                                    X, \n",
    "                                    dt, \n",
    "                                    prior_init=None, \n",
    "                                    hyper_prior=(alpha_prior, beta_prior), \n",
    "                                    tol=1e-4, \n",
    "                                    max_iter=500)[2][0])\n",
    "\n",
    "dL_ddt = jax.grad(lambda y: SBL(fixed_point_solver_explicit, \n",
    "                                    theta, \n",
    "                                    y, \n",
    "                                    prior_init=None, \n",
    "                                    hyper_prior=(alpha_prior, beta_prior), \n",
    "                                    tol=1e-4, \n",
    "                                    max_iter=500)[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "particular-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    grad_theta_exp = dL_dtheta(theta)\n",
    "    grad_dt_exp = dL_ddt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "divided-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 4.0315060e+01, -7.8661844e-02,  2.5311833e+02, ...,\n",
       "               1.2050523e+00,  1.3337393e+00, -6.8289971e-01],\n",
       "             [ 4.2319916e+01, -8.1662700e-02,  2.4128146e+02, ...,\n",
       "               1.2297906e+00,  1.3528125e+00, -6.8435913e-01],\n",
       "             [ 4.4433788e+01, -8.4824540e-02,  2.2870581e+02, ...,\n",
       "               1.2557112e+00,  1.3726672e+00, -6.8576968e-01],\n",
       "             ...,\n",
       "             [-5.3714981e+00, -5.8753863e-03,  3.5168759e+02, ...,\n",
       "               3.2359827e-01,  3.5291189e-01, -4.1627902e-01],\n",
       "             [-3.9541931e+00, -8.0396160e-03,  3.4455737e+02, ...,\n",
       "               3.4352410e-01,  3.7065768e-01, -4.1905183e-01],\n",
       "             [-2.5585327e+00, -1.0170683e-02,  3.3754132e+02, ...,\n",
       "               3.6315131e-01,  3.8813728e-01, -4.2178833e-01]],            dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_theta_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "greatest-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_dt_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "incorporate-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(False, dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_theta_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dated-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(False, dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_dt_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-darkness",
   "metadata": {},
   "source": [
    "No nan- seems fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-writing",
   "metadata": {},
   "source": [
    "So its not fast but we're getting results. Now let's run a pass using the implicit diff method and compare the results - they should be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "geological-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    loss, coeffs, prior, metrics= SBL(fixed_point_solver_implicit, \n",
    "                                        theta, \n",
    "                                        dt, \n",
    "                                        prior_init=None, \n",
    "                                        hyper_prior=(alpha_prior, beta_prior), \n",
    "                                        tol=1e-4, \n",
    "                                        max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wicked-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-234.16995 [[ 2.8810082e-03]\n",
      " [-5.4706748e-06]\n",
      " [ 5.0718643e-02]\n",
      " [-1.0429989e-04]\n",
      " [ 7.3084915e-01]\n",
      " [ 4.2338760e-04]\n",
      " [-2.3527378e-04]\n",
      " [ 5.7718530e-04]\n",
      " [ 2.4089876e-04]\n",
      " [ 5.9699081e-04]\n",
      " [ 5.5704353e-04]\n",
      " [-3.3291994e-04]] [1.2790438e+04 2.7565962e+03 5.8328896e+01 4.3157676e+03 1.4594887e+00\n",
      " 1.0524597e+02 1.9473764e+02 4.4398584e+02 1.3007578e+02 1.2405847e+01\n",
      " 2.1486467e+01 4.7296772e+01 2.1528165e+00] (50, DeviceArray(9.250849e-05, dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(loss, coeffs, prior, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-journey",
   "metadata": {},
   "source": [
    "Forward pass is the same as it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "upset-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dtheta_imp = jax.grad(lambda X: SBL(fixed_point_solver_implicit, \n",
    "                                                            X, \n",
    "                                                            dt, \n",
    "                                                            prior_init=None, \n",
    "                                                            hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                            tol=1e-4, \n",
    "                                                            max_iter=500)[0])\n",
    "\n",
    "dL_ddt_imp = jax.grad(lambda y: SBL(fixed_point_solver_implicit, \n",
    "                                                            theta, \n",
    "                                                            y, \n",
    "                                                            prior_init=None, \n",
    "                                                            hyper_prior=(alpha_prior, beta_prior), \n",
    "                                                            tol=1e-4, \n",
    "                                                            max_iter=500)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "solar-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.disable_jit():\n",
    "    grad_theta_imp = dL_dtheta_imp(theta)\n",
    "    grad_dt_imp = dL_ddt_imp(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-mongolia",
   "metadata": {},
   "source": [
    "That worked - now let's check if they're similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ambient-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(True, dtype=bool)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.any(jnp.isnan(grad_theta_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stable-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(nan, dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(jnp.abs(grad_theta_exp - grad_theta_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "challenging-taxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(nan, dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(jnp.abs(grad_dt_exp - grad_dt_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-amsterdam",
   "metadata": {},
   "source": [
    "Okay so as usual the implicit method gives a nan. The best approach for now is to get the jit version of the explicit method working and see that one - that would give us a) something working at least and b) something to compare the SBL with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-leadership",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
